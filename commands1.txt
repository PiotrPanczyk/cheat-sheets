MY GEID: 1000672492
New: 0800 368 0634
New New: 5552255
From Belfast use dial-in: 028 9595 0023
Passcode: 281 563 9417
Moderator Security Code: 978 746 4300  --> to open - dial 0800 368 0634 and enter 978 746 4300
------------------------------------------------------------------------------
NAM Application/CSI ID/Owner Name/Owner GEID: GMD/165503/Doug Leyens/1000183038
CSI ID:
165503 - Global GMD
168082 - EMEA GMD
Chris Tattersall owns GMD BOW prioritisation
From the Tech side anything would need to also go by Amit Rijhsinghani
ServiceNow:
Primary App: GLOBAL MARKET DATA PLATFORM
Primary App Instance: GLOBAL MARKET DATA PLATFORM~EMEA~PROD
Group: ICG EM AD GB EMEA MARKET DATA
------------------------------------------------------------------------------
Prod Support Project - put hours against if doing L3 support.
3 Production Support for Global Market Data & Colordata Globally
------------------------------------------------------------------------------
Please find below consolidated upcoming Freezes that will help you in planning.

?  Broadridge 418 Freeze: Oct 15 - 22 
?  Irish Presidential Elections:  Nov 3-10
?  MSCI Rebalance: Dec 28-30
?  Infrastructure change freeze: Dec 7 
?  Application change freeze: Dec 9 - Jan 3
-------------------------------------------------------------------------------

GMD SFTP NY:
sft-ny4p.prod.lava - PROD password
------------------------------------------------------------------------------
P2P Approver: Steven Seybold
TISO (Technical Information Security Officer): Sutton, Jeremy  
BISO (Business Information Security Officer):  Khan, Adeel - 1010706480 
GISO (Group Information Security Officer):     Kelly , Arleen  
------------------------------------------------------------------------------
NEW SCSU #############################################
 - pbrun cticker (replacing scsu - cticker) 
 - pbrun rpm (replacing scsudo root /bin/rpm)
 -----------------------------------------------------
 SCSU on STI:
 sudo su cticker
 -----------------------------------------------------
pbrun -u gmdemea dap
 
scapdap - SCSU on new boxes
Prefix nohup to command to start app
Eg.
bash-3.2$ nohup /opt/cticker/scripts/start.sh mamacache mamacache_boat_p &
“exit” then takes you back to jump box as cticker.
Jump boxes: eqctic35p,44p
----------------------------------------------------------------------------
Cloud VMs under my name:
gmd-replay-dev-1.nam.nsroot.net - 	Your cloud VM sd-7490-fbd5 associated with the CMP ID WS55644175-00001
gmd-replay-dev-2.nam.nsroot.net -	Your cloud VM sd-3bff-1f0b associated with the CMP ID WS55644737-00001 
gmd-replay-dev-3.nam.nsroot.net - 	Your cloud VM sd-8daf-38de associated with the CMP ID WS55644254-00001
gmd-replay-dev-4.nam.nsroot.net  -	Your cloud VM sd-ad0c-bf37 associated with the CMP ID WS55643714-00001 
									Your cloud VM sd-0f1c-3e4a associated with the CMP ID WS55671992-00001 
									Your cloud VM sd-145d-2c75 associated with the CMP ID WS55672001-00001  
									Your cloud VM sd-5d01-bfa0 associated with the CMP ID WS55671996-00001
									Your cloud VM sd-a91e-821c associated with the CMP ID WS55672009-00001 
									
----------------------------------------------------------------------------
GMD SFTP:
sftp sft-ny4p.prod.lava
Basic Commands   #######################################
df -vh - disk usage
du -sh [directory]
Shows size of directories:
du -k | sort -n | perl -ne 'if ( /^(\d+)\s+(.*$)/){$l=log($1+.1);$m=int($l/log(1024)); printf  ("%6.1f\t%s\t%25s  %s\n",($1/(2**(10*$m))),(("K","M","G","T","P")[$m]),"*"x (1.5*$l),$2);}'
stat <file> - shows when was the file last accessed and by what user
tar -xzvf - untar
tar -czvf - tar and zip
tar -ztvf - list files in tar.gz
rpm -qlp - list rpm
tail -f <filename>
lcd (local change dir) - change dir on local box when you are on sftp
grep -A 1 WmwPort - line after the occurance of WmwPort text
rm -r directory - remove dir with files inside
cat /etc/redhat-release - red hat version
ln -s ../init.d/httpd S77httpd - create symbolic link.
find $DEST_1 -maxdepth 1 -type f -mtime +8 -exec rm {} \; -maxdepth 1 - prevents find to dig in to subdirectories (deletes files older than 8 days)

Windows vs. Unix line endings
Unix: \n
Win: \r\n
Find out what fomratin file is using run:
file filename 
ex: [gmdemea@uk1qgmd01 equities]$ file OptiqXdubSymbols.csv
OptiqXdubSymbols.csv: ASCII text, with CRLF line terminators
tr -d '\r' < input.file > output.file - convert dos line endings to unix.
VIM - set ff=unix

find . -name "*.*pp" |xargs grep -i createsymbolcache - find with grep
pkill string
cat /etc/redhat-release or vi /proc/version or uname -a - linux version
1,$s/<start>[0-9][0-9]:[0-9][0-9]<\/start>/<start>10:15<\/start>/ - substitute mamaperf start times in vi
SSH to eqctic30p -> ssh -t eqctic30p bash
~. -when ssh hangs on exit
xmllint - check xml syntax
netstat -ge - multicast groups
netstat -tulpn | grep 5501 - check what is using port
Check bonding bond network interface
less /proc/net/bonding/bond0
-------------------------------------------------------------------
chmod 644 filename - Owner: read/write, Group: read, World: read
The numbers represent the Owner, the Group and Everyone else
What the numbers mean	
		1. 7 : Read, Write & Execute
		2. 6 : Read & Write
		3. 5 : Read & Execute
		4. 4 : Read Only
		5. 3 : Write & Execute
		6. 2 : Write Only
		7. 1 : Execute Only
		8. 0 : None
-----------------------------------------------------------------------
Get symbols from a range (partition) like A-G, H-R, S-Z using ASCII
The input param is a symbol like VOD.L. The command will get first character check if it is in the range and return it. 
If not in range it will not return anything. 
Provide the lower and upper params into awk as capital letter in the -v param. 
If lower is A than characters like '.' and '=' and digits will be added into the range.
echo sNPP.PA | awk -v lower="S" -v upper="Z" 'BEGIN{ for(c=0;c<256;c++){ord[sprintf("%c", c)]=c;} l1=ord[lower]; u1=ord[upper]; l2=ord[tolower(lower)]; u2=ord[tolower(upper)]; if(lower == "A"){l1=46} } {firstChar=substr($1,1,1); if( (ord[firstChar]>=l1 && ord[firstChar]<=u1) || (ord[firstChar]>=l2 && ord[firstChar]<=u2) ){print $1} }'

export TMOUT=0 - prevent putty timeout.
ls -l /proc/27797/fd | wc -l - check the number of opened files (file descriptors)
tr  '\037' '|'   - replace unit separator control character
sysctl -a|grep rmem   - buffer kernel memory settings

Find and remove XFRA stocks from overwrite.
for i in $(cat XFRA_maps.csv); do isin=$(echo $i |awk 'BEGIN {FS=","} {if($2 != ""){split($2, arr, "."); print arr[1]}}'); if [[ ! -z "$isin" ]] ;then echo "$isin"; grep -l $isin * |xargs sed -i "/$isin/d"; fi; done

-------------------------------------------------------------------------------------------------------------------------------------
Linux and ram memory usage
How do I see how much free ram I really have?
To see how much ram your applications could use without swapping, run free -m and look at the "available" column:
$ free -m
              total        used        free      shared  buff/cache   available
Mem:           1504        1491          13           0         855      792
Swap:          2047           6        2041

(On installations from before 2016, look at "free" column in the "-/+ buffers/cache" row instead.)

This is your answer in megabytes. If you just naively look at "used" and "free", you'll think your ram is 99% full when it's really just 47%!
Info from: https://www.linuxatemyram.com/
-------------------------------------------------------------------------------------------------------------------------------------------
GMD servers model / generation G7 G8 G9
uk1pgmd18.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod
uk1pgmd19.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod
uk1pgmd20.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod
uk1pgmd21.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod
uk1pgmd22.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod
uk1pgmd23.prod.lava,6Server,HP,ProLiant DL380 Gen9,Prod 
uk1pgmd10.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd11.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd12.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd13.prod.lava,6Server,HP,ProLiant DL380 G7,Prod 
uk1pgmd14.prod.lava,6Server,HP,ProLiant DL380 G7,Prod 
uk1pgmd16.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd17.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd01.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd02.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd03.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd04.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd05.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd06.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd07.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd08.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
uk1pgmd09.prod.lava,6Server,HP,ProLiant DL380p Gen8,Prod 
-------------------------------------------------------------------------------------------------------------------------------------------
Current IRQ set-up
uk1pgmd01
/usr/sbin/sfcirqaffinity eth4 -c 13,14,15
/usr/sbin/sfcirqaffinity eth5 -c 13,14,15
/usr/sbin/sfcirqaffinity eth14 -c 13,14,15
/usr/sbin/sfcirqaffinity eth15 -c 13,14,15

uk2pgmd01
/usr/sbin/sfcirqaffinity eth12 -c 14,15       CHG0002875142
/usr/sbin/sfcirqaffinity eth13 -c 14,15       CHG0002875142
/usr/sbin/sfcirqaffinity eth14 -c 14,15       CHG0002875142
/usr/sbin/sfcirqaffinity eth15 -c 14,15       CHG0002875142

uk2pgmd07
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd07
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd08
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk2pgmd08
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd09
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk2pgmd09
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd10
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk2pgmd10
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd11
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk2pgmd11
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd12
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk2pgmd12
/usr/sbin/sfcirqaffinity eth12 -c 14,15
/usr/sbin/sfcirqaffinity eth13 -c 14,15
/usr/sbin/sfcirqaffinity eth14 -c 14,15
/usr/sbin/sfcirqaffinity eth15 -c 14,15

uk1pgmd13
/usr/sbin/sfcirqaffinity eth4 -c 11
/usr/sbin/sfcirqaffinity eth5 -c 11
/usr/sbin/sfcirqaffinity eth6 -c 11
/usr/sbin/sfcirqaffinity eth7 -c 11
/usr/sbin/sfcirqaffinity eth13 -c 11
/usr/sbin/sfcirqaffinity eth15 -c 11

uk2pgmd13
/usr/sbin/sfcirqaffinity eth4 -c 11
/usr/sbin/sfcirqaffinity eth5 -c 11
/usr/sbin/sfcirqaffinity eth6 -c 11
/usr/sbin/sfcirqaffinity eth13 -c 11
/usr/sbin/sfcirqaffinity eth14 -c 11
/usr/sbin/sfcirqaffinity eth15 -c 11

uk1pgmd14
/usr/sbin/sfcirqaffinity eth4 -c 10,11
/usr/sbin/sfcirqaffinity eth5 -c 10,11
/usr/sbin/sfcirqaffinity eth6 -c 10,11
/usr/sbin/sfcirqaffinity eth7 -c 10,11
/usr/sbin/sfcirqaffinity eth13 -c 10,11
/usr/sbin/sfcirqaffinity eth15 -c 10,11

uk2pgmd14
/usr/sbin/sfcirqaffinity eth4 -c 10,11
/usr/sbin/sfcirqaffinity eth5 -c 10,11
/usr/sbin/sfcirqaffinity eth6 -c 10,11
/usr/sbin/sfcirqaffinity eth13 -c 10,11
/usr/sbin/sfcirqaffinity eth14 -c 10,11
/usr/sbin/sfcirqaffinity eth15 -c 10,11
-------------------------------------------------------------------------------------------------------------------------------------------


Check Corefile dir: vi /proc/sys/kernel/core_pattern

Replace whitespace with new line in VIM: 1,$s/\s\+/\r/
or 
:1,$s/\S\zs \+/\r/  -- treats tab same as space
echo "${ttt//[[:blank:]]/}|"

Replace string on multiple files:
grep -rl matchstring somedir/ | xargs sed -i 's/string1/string2/g' - -r -recursive - go into sub directories
grep -l ATD_ * | xargs sed -i 's/ATD_/RDC_/g'
grep -rl ATD_ . | xargs sed -i 's/ATD_/RDC_/g'
grep -l QBUS_HOME * | xargs sed -i '/QBUS_HOME/QBUS_DIR/g'

To remove the line and print the output to standard out:
sed '/pattern to match/d' ./infile

To directly modify the file:
sed -i '/pattern to match/d' ./infile

To directly modify the file (and create a backup):
sed -i.bak '/pattern to match/d' ./infile

# Replace 0.0 price and 0 volume with empty field on delete orders
sed -E -i 's#(\|Action:D\|)([0-9A-Z]{12,16}\|)(B|S)\|0\.0\|0#\1\2\3\|\|#'


Start / Stop / run command on all PROD servers:
Paddys python:
1. Kill all CGC: for i in $(cat host_cgc); do echo $i ; ssh -q $i "/opt/gmdemea/versions/devops/EMEA/EMEA_START_STOP/start_stop.py -k"; done 
2. Start all CGC: for i in $(cat host_cgc); do echo $i ; ssh -q $i "/opt/gmdemea/versions/devops/EMEA/EMEA_START_STOP/start_stop.py -s"; done 

From uk1dgmd01
for i in $(cat /tmp/host); do echo $i; ssh -q $i "kill \$(ps -u gmdemea | grep GMDMain | awk '{print \$1}')"; done 
[gmdemea@uk1dgmd01 runCommandMultipleHosts]$ for i in $(cat cgcGmdsHosts.txt); do echo $i; ssh -q $i "eval \$(crontab -l | grep \"^[^#].*gmdserver_start\" | cut -d ' ' -f 7-) &"; done

Stop / Start all PreProd feeds om uk1qgmd01
for i in $(grep -l rfa_pp.cfg /opt/gmdemea/qbus/config/* | cut -d '_' -f 2- | cut -d '.' -f 1 | grep _pp); do crontab -l | grep "^[^#].*qbus_start.*$i" | cut -d ' ' -f 7-; done

Script:
#!/bin/bash
while read line
do
        ssh -q "$line" "/opt/gmdemea/scripts/SVNRepoUpdate.sh" < /dev/null
done < "$1"
-------------------------
TMUX tmux - provides nice session with tabs and split screen functionality, keeps session alive.
It is installed on ny3-ldev04.dev.sti

Set ctrl+a as prefix instead the default ctrl+b
set -g prefix C-a
unbind-key C-b
bind-key C-a send-prefix 

.tmux.conf  

Copy between tmux panes / windows
Ctrl + a , [ Enter copy(?) mode.
Move to start/end of text to highlight.
Ctrl space. ...
Move to opposite end of text to copy.
Alt + w Copies selected text into tmux clipboard. ...
Move cursor to opposite tmux pane, or completely different tmux window. ...
Ctrl + b , ] Paste copied text from tmux clipboard.

-------------------------
Use this command to find all deleted processes which are holding all your space and kill them. They are owned by App ID.
lsof | grep "(deleted)"
lsof -p <pid> to list its open files and their sizes

Update: A commenter suggested a way to disable CTRL+S from sending XOFF altogether:
    add this to your .bashrc (man stty for more options):
    stty ixany
    stty ixoff -ixon
To truncate opened file to avoid filling the disk without killing application:
: > /path/to/the/file.log  -- or use 'truncate' command.
If it was already deleted, on Linux, you can still truncate it by doing:
: > "/proc/$pid/fd/$fd"
Where $pid is the process id of the process that has the file opened, and $fd one file descriptor it has it opened under (which you can check with lsof -p "$pid"
Linux kernel log:
/var/log/messages
Print orders where time delay is more than 1 sec - binary protocol.
awk 'BEGIN {FS=","} /Order_Book_Intheader=message_type=15/ {split($10, ex, "="); split($11, cdi, "=");  res = cdi[2] - ex[2]; printf "Diff: %s\nExc Epoch: %s - Exc Time: %s - %s ms\nAck Epoch: %s - Ack Time: %s - %s ms\n%s\n\n", res, ex[2], strftime("%c",(ex[2] / 1000000000)), (substr(ex[2], 11) / 1000000), cdi[2], strftime("%c",(cdi[2] / 1000000000)), (substr(cdi[2], 11) / 1000000), $0}' GEPH_PA-GMDBridge.log
Analyse GMD server internal latency stats from log file:
awk 'BEGIN { maxMin = 0; avgMin = 0; maxMax = 0; avgMax = 0; maxAvg = 0; avgAvg = 0; } /^(0[8-9]|1[0-6]).*latency Stats/ {str = $7$9$11; split(str, arr, ":"); minSum+=arr[2]; maxSum+=arr[3]; avgSum+=arr[4]; count+=1; if (arr[2] > maxMin) maxMin = arr[2]; if(arr[3] > maxMax) maxMax= arr[3]; if(arr[4] > maxAvg) maxAvg = arr[4]; if(arr[3] > 1000000) {print $0; maxDelay1+=1;} printf "Min: %s us - Max: %s us - Avg: %s us\n", arr[2], arr[3], arr[4];} END { printf "\n-----------------------SUMMARY\nMax Min=%s us | Max Max=%s us | Max Avg=%s us\n Avg Min=%s | Avg Max=%s | Avg Avg=%s\n No. of Max Latency over 1 second=%s\n",maxMin, maxMax, maxAvg, minSum / count, maxSum / count, avgSum / count, maxDelay1 }' GMDServer_HR.1.log
Change line separator and field separator to make searching easier:
awk 'BEGIN{RS="\n\n"; FS="\n"} {if(($0 ~ /XSWX/) && ($0 ~ /XLON/)){print}}'
RS - line separator
FS - field separator
Search for crosses in BookBuilder recording:
awk 'BEGIN{RS="^|-*-|-*-|\n$"; FS="\|";} {bid=$5; ask=$6; gsub(/ /, "", bid); gsub(/ /, "", ask); if(bid ~ /^[0-9]/) {if(bid >= ask) {print "Top book cross: "bid">="ask"\n"$0"\n==================================\n"}}}' 20160411.GMD_raw_bookmsgs.log > 20160411.ISPA.AS_Crosses.txt
--------------------------------------------------------------------
Finds duplicate lines in file
below will display the no of occurrence and the record
> sort f1.txt|uniq -c
   2 abc 1000 3452 2463 2343 2176 7654 3452 8765 5643 3452
   1 aer 1000 3452 2463 2343 2176 7654 3452 8765 5643 3452
   2 tas 3420 3562 2123 1343 2176 7654 3252 8765 5643 3452
below will display only the duplicate records
> sort f1.txt|uniq -d
abc 1000 3452 2463 2343 2176 7654 3452 8765 5643 3452
tas 3420 3562 2123 1343 2176 7654 3252 8765 5643 3452
below will display distinct records
> sort f1.txt|uniq
abc 1000 3452 2463 2343 2176 7654 3452 8765 5643 3452
aer 1000 3452 2463 2343 2176 7654 3452 8765 5643 3452
tas 3420 3562 2123 1343 2176 7654 3252 8765 5643 3452
--------------------------------------------------------------------------
Extract RPM:
rpm2cpio GMDClientAPI-1.0.7-1.x86_64.rpm | cpio -idmv
for rpm in *.rpm; do rpm2cpio $rpm | cpio -idumv; done

Get Service ID and mcast IPs from SMDS config:
awk '/<MDLineHandler/ {for(i=1;i<NF;i++){split($i,arr,"="); if(arr[1]=="service-id" || arr[1]=="name" || arr[1]=="primary-mc-channel" || arr[1]=="secondary-mc-channel"){print $i}}}' utp_xpar.xml
SMDS Recovery / Retrans checks:
grep "Recovery login successful"
grep "Retrans"
grep "Login response for snapshot received"
grep "Snap"

Prepare CDITester trade format for vimdiff:
awk 'BEGIN{FS="|"} /EquityTradeU.*CRH\.I.*XDUB/ {printf "%s|%s|%s|%s|%s|%s|%s|%s|%s\n", $2,$3,$6,$7,$9,$10,$11,$13,substr($14,0,length($14)-4)}' 20170526.CDIClientUpdates_p1.log > QA_XDUB_Trades.txt
Prepare CDITester trade recap format for vimdiff:
awk 'BEGIN{FS="|"} /EquityTradeR.*GDRB\.BU/ {printf "%s|%s|%s|%s|%s|%s|%s|%s\n", $2,$7,$8,$9,$10,$11,$12,substr($20,12,length($20)-4)}' PP_XBUP_TradesRecap.txt
Prepare CDITester order format for vimdiff:
awk 'BEGIN{FS="|"} /EquityLimit.*BNPP\.PA.*XPAR/ {printf "%s|%s|%s|%s|%s|%s|%s|%s|%s\n", $2,$3,$4,$5,$10,$11,$12,$14,substr($15,12,length($15))}' PP_Orders_BNPP.txt > PP_Orders_BNPP.txt
Prepare CDITester inside (top of book) format for vimdiff:
awk 'BEGIN{FS="|"} /EquityInside.*JMT\.LS.*XLIS/ {printf "%s|%s|%s|%s|%s|%s|%s|%s\n", $2,$3,$8,$9,$11,$12,$14,substr($15,12,length($15))}' PP_Orders_BNPP.txt > PP_Formated_Orders_BNPP.txt
Prepare CDITester Imbalance format for vimdiff:
awk 'BEGIN{FS="|"} /EquityImb.*ABBN\.S/ {printf "%s|%s|%s|%s|%s|%s|%s|%s|%s|%s\n", $2,$3,$4,$8,$9,$12,$13,$17,$20,substr($21,12,length($21))}' RDC_CDIClientUpdates_p1.log > RDC_ABBN.S_Imbalance_Formated.txt
Prepare CDITester Security status (EquityQuoteIndicator) for vimdiff:
awk 'BEGIN{FS="|"} /EquityQuoteInd.*BNPP\.PA/ {printf "%s|%s|%s|%s|%s|%s\n", $2,$3,$4,$7,$8,substr($9,12,length($9))}' prod/CDIClientUpdates_p1.log > prod/UTP_BNPP.PA_SecurityStatus.txt

Find significant decimal in Swiss (XSWX, XVTX) ref file by ISIN
awk 'BEGIN{FS="\t"} /^CH0011037469/ {printf "%s, %s, %s\n", $1, $2, $45}' TradedInstrument.txt
--------------------------------------------------
Adding Network Routes (TCP) 
netstat -rn shows all the routes on the host: 
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
46.30.98.192    0.0.0.0         255.255.255.240 U         0 0          0 bond1.202
90.204.92.64    0.0.0.0         255.255.255.240 U         0 0          0 bond1.211
10.150.129.0    10.151.129.254  255.255.255.0   UG        0 0          0 bond1.300
10.151.129.0    0.0.0.0         255.255.255.0   U         0 0          0 bond1.300
169.182.172.0   0.0.0.0         255.255.255.0   U         0 0          0 eth0
156.48.97.0     46.30.98.206    255.255.255.0   UG        0 0          0 bond1.202
0.0.0.0         169.182.172.1   0.0.0.0         UG        0 0          0 eth0
to add a route use:
ip route add 156.48.97.0/24 via 46.30.98.206 dev bond1.202
where in this example 156.48.97.xxx is the exchange Recovery server, the 46.30.98.206 is the Subnet given in table below:
https://www.citi.net/confluence/display/165503/Fixnetix+Connectivity
and the bond1.201 is the vlan tagged interface to add this to.
We can then persist this route for a server restart by adding a route entry here:
/etc/sysconfig/network-scripts
route-bond1.202
156.48.97.0/24 via 46.30.98.206
More info: http://confluence.atdesk.com/confluence/display/TG/soniQ#soniQ-OperatingSystemandSolarflareTuning

Get interface with dropped packets from netstat:
ifconfig | awk 'BEGIN{RS="\n\n"} {split($0, flds); for(i=1; i<length(flds); i++){if(flds[i] ~ /dropped:/){split(flds[i], arr, ":"); if(arr[2]>0){print $0}}}}'
--------------------------------------------------
vim match command to highlight specific text 
:match Todo /symbol\|price/|size\|side\|mktCtrId\|feedId\|GMDQuoteMsg\|GMDTradeMsg\|GMDImbalanceMsg\|GMDInstrumentStatusMsg\|GMDStaticInfoMsg\|GMDSnpshotCompleteNotification\|GMDCacheClearMsg\|GMDTradeMsgDetailed/

vim comment / uncomment
vim block editing:
CTRL-V - block editing mode
Select rows with cursor
Shift -i - insert mode 
Enter text (will show only on the first row)
Esc - to apply to all rows

block editing remove uncomment
CTRL-V
select column with arrows
press x to delete


vi - paste unmodified text:
:set paste
:set nopaste
:set paste
set pastetoggle=<F2>

g - global
:g/pattern/cmd - where cmd may be p-print, d-delete

vim count matching lines with n flag (counts number of hits; no changes occur):
:%s/pattern//gn

vimdiff copying differences between sides:
Use dp for copying the current difference block to another side, do for copying from another side to the current. 
dp means "put", do means "obtain". The current difference block is where your caret is.
You can also use the commands :[range]diffget and :[range]diffput, meaning if you've already reviewed all differences in the whole file, 
you can do :1,$diffput or :1,$diffget to move all diffs from or to, respectively, the current buffer.

]c :        - next difference
[c :        - previous difference
do          - diff obtain
dp          - diff put
zo          - open folded text
zc          - close folded text
:diffupdate - re-scan the files for differences
:vimdiff -c 'set diffopt+=iwhite' - vimdiff ignore whitespace

Define array 'fs' of file names to do changes on and run to open diffs in a loop:
for i in ${fs[@]} ; do vimdiff $i ../../../rdc/primary/superbook_0G/$i; done
---------------------------------------------------
CTRL + r - search command history
rpm -qa | grep jdk - java version
/usr/java/jdk-1.6.0_16/bin/java -version
If CPU over 90% it will log it to the file:
top -b | awk '{if($1 !~ /top|Mem:|Swap:|Tasks:/){if($9 > 90.0) print $0}}' > /var/tmp/topCpu.txt
top -c -> full proces names
Getting wPrevClosePrice from symbol file
awk '/wPrevClosePrice/ {for(i=1;i<=NF;i++) {if(match($i, "wPrevClosePrice")){printf " %s - %s: %s ", substr($10, 17, length($10)), "wPrevClosePrice", substr($i, 23, length($i))}}printf "\n"}'  ISIN.CURR.sym
REGEX:
Find what: ^(.*?)\s+(.*?)\s+(.*?)\s+(.*?)\s+(.*?)\s+(.*?)\s+(.*) - create insert from output of select statement from configuration table in notepad++
Replace with: (\1, \2, \3, '\4', '\5', '\6', '\7'),
JIRA Advanced Search Query:
summary ~ ColorData OR description ~ ColorData OR comment ~ ColorData order by created

Uncomment, remove # from lines matched by regex in VIM crontab using regex backreferences
:%s:\(^#\)\([0-9].*_pp.*\):\2:

---------------
Java Heap Size:
You can increase or change size of Java Heap space by using JVM command line option -Xms, -Xmx and -Xmn. 
don't forget to add word "M" or "G" after specifying size to indicate Mega or Giga. 
for example you can set java heap size to 256MB by executing following command java -Xmx256m HelloWord.
Read more: http://javarevisited.blogspot.com/2011/05/java-heap-space-memory-size-jvm.html#ixzz1upDi82Pe
CitiSmart - Here are our performance related params:
PERF_OPT=" -XX:+AggressiveOpts -XX:+UseCompressedOops -XX:+OptimizeStringConcat -XX:+UseStringCache -XX:+UseFastAccessorMethods "
---------------
Spoof FID in JVM:
-Duser.name=gmdemea

Linux Optimisation:
cat /proc/cpuinfo --> CPU info
taskset -p -c <pid> - retrieve process CPU affinity
cset:
Assuming that you have a GMD cset using cores 4 and 6 you would run:
cset proc –e –s GMD -- chrt –p 99 onload cdsmain –c config/cdc.cfg
The –e means execute a command, -s specifies the cset, and the double dash tells cset that the options after that are for the command.
GMD cset affinity script (own by gmdemea but run from root crontab):
/opt/gmdemea/scripts/affinity.sh
Create cset
cset set -c 0,1,2 -m 0 system
Remove cset 
cset set -d cset_name
List cset
cset set -l
-------- ISOLCPUS - to isolate cores for user apps --------------------
For example in NAM we isolate cores 4-19 for GMD  and can be checked via boot parameter here:
[ms10067@ny4pgmdhb01 ~]$ cat /proc/cmdline
ro root=/dev/mapper/rootvg-lroot rd_NO_LUKS LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 rd_LVM_LV=rootvg/lroot crashkernel=137M@0M KEYBOARDTYPE=pc KEYTABLE=us rd_LVM_LV=rootvg/lswap rd_NO_DM processor.max_cstate=0 nohz=off timer=tsc intel_idle.max_cstate=0 isolcpus=4-19
Verify if islocpus have actually isolated cores:
For that, you would use:
$cat /proc/cmdline 
ro root=/dev/mapper/rootvg-lroot rd_NO_LUKS LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 rd_LVM_LV=rootvg/lroot crashkernel=137M@48M  KEYBOARDTYPE=pc KEYTABLE=us rd_LVM_LV=rootvg/lswap rd_NO_DM rhgb quiet nohz=off processor.max_cstate=0 timer=tsc intel_idle.max_cstate=0 isolcpus=2-15
As you can see, in this particular example isolcpus=2-15 was passed as an argument to the running kernel.
You can also use taskset pointed to PID 1. As PID 1 is the standard PID for the first task launched by the kernel, 
we can take as a pretty good indication that it will reflect wether we have isolcpus working. As in:
[gmdemea@uk1qgmd02 ~]$ taskset -pc 1
pid 1's current affinity list: 0,1
Comparing with the lscpu command in the same server:
[gmdemea@uk1qgmd02 ~]$ lscpu | grep CPU.s
CPU(s):                16
On-line CPU(s) list:   0-15
NUMA node0 CPU(s):     0-7
NUMA node1 CPU(s):     8-15
We can see that server has 0=15 cores but system task PID 1 is assigned only 0,1
NUMA numa node commands:
Numa CPU and memory Info: numactl -H
Get existing numa nodes: numactl -H | grep -Eo 'node ([0-9])' | sort -u | cut -d' ' -f2
Get CPUs per numa: numactl -H | grep "node 0 cpus:" | sed 's/node [0-9] cpus: //g' | sed 's/\s/,/g' 
---------------------------------
chrt - priority and schedule - http://www.cyberciti.biz/faq/howto-set-real-time-scheduling-priority-process/
chrt -p 99 <PID> - setting priority to 99 (RT - real time)
chrt -o -p 0 <PID> - setting back to default
Check if server has SolarFlare card:
lspci -vvv |grep -i solar
If has:
24:00.0 Ethernet controller: Solarflare Communications SFC9020 [Solarstorm]
        Subsystem: Solarflare Communications SFN6122F-R7 SFP+ Server Adapter
24:00.1 Ethernet controller: Solarflare Communications SFC9020 [Solarstorm]
        Subsystem: Solarflare Communications SFN6122F-R7 SFP+ Server Adapter
		
Command to know if an interface is SolarFlare:
$ethtool -i eth4 | grep driver
driver: sfc
		
SolarFlare NUMA assignment:
cat /sys/class/net/eth12/device/numa_node
----------------------------------------------------
SolarFlare kernel bypass - onload
- onload_stackdump processes --> show processes using onload
#pid      stack-id cmdline
25257     6        /opt/gmdemea/gmdserver/bin/release/cdsmain -c /opt/gmdemea/gmdserver/config/ice-embeded-gmdserver/cd_nlvls.cfg
onload_stackdump 6 lots --> show stats for specific process - stack-id = 6
- Onload stack numa allocation (should be same NUMA as SF card and application):
GMDS:
onload_stackdump lots | grep numa
numa nodes: creation=1 load=1 
creation - memory allocation node
load - onload driver load node
Qbus:
onload_stackdump 34 lots | grep numa
numa nodes: creation=0 load=0
- Check receive descriptor queue size
onload_stackdump lots | grep EF_RXQ_SIZE
- EF_PREFAULT_PACKETS - pre allocated packets.
onload_stackdump 2 packets
When deciding how many packets to prefault, 
the user should look at the alloc value when the onload_stackdump packets command is run. 
The alloc value is a high water mark identifying the maximum the number of packets being used by the stack at any singular point. 
Setting EF_PREFAULT_PACKETS to at least this value is recommended.
- Processing at User-Level
onload_stackdump 2 lots |grep polls
k_polls
Number of times the socket event queue was polled from the kernel.
u_polls
Number of times the socket event queue was polled from user space.
periodic_polls
Number of times a periodic timer has polled for events.
interrupt_polls
Number of times an interrupt polled for network events.
deferred_polls
Number of times poll has been deferred to the stack lock holder.
timeout_interrupt_polls
Number of times timeout interrupts polled for network events.
- As Few Interrupts as Possible
onload_stackdump lots | grep ^interrupt
- Onload drops:
onload_stackdump 2 lots | grep drop
- Lock Contention
onload_stackdump 2 lots | egrep "(lock_)|(sleep)"
Lock contention can greatly affect performance. 
When threads share a stack, a thread holding the stack lock will prevent another thread from doing useful work. 
Applications with fewer threads may be able to create a stack per thread (see EF_STACK_PER_THREAD and Stacks API on page 214).
- Check if onload in operation:
onload_stackdump lots |grep udp_tot
udp_tot_recv_pkts_ul: 145229298 --> 'ul' - with kernel bypass
udp_tot_recv_drops_ul: 0
udp_tot_recv_pkts_os: 1 --> 'os' - no bypass
udp_tot_send_pkts_ul: 4200
udp_tot_send_pkts_os: 1

Onload network changes:
Beside SMDS configs LBM for QBUS and SUB Checks needs to be changed:
QBUS:
/opt/gmdemea/qbus/config/publisher.xml:
<option name="resolver_multicast_interface" default-value='"bond1.300"' /> (was bond12)
/opt/gmdemea/qbus/config/receiver.xml
<option name="resolver_multicast_interface" default-value='"bond1.201"' /> (was bond0)
Sub Checks and other apps:
/opt/gmdemea/tools/config/lbm/receiver.xml
<option name="resolver_multicast_interface" default-value='"bond1.300"' />
IRQ:
Check IRQ affinity for SF:
cat /proc/interrupts | grep eth12
I have changed the script to use 4 cores so it is using core masks 0x1, 0x2, 0x4, 0x8 and assign all the IRQ to this 4 masks. I have never played with this so want to check if I am not completely wrong.
/usr/bin/set_irq_affinity.sh
The script is (my change in red):
#/bin/bash
if [ -z $1 ]; then
        echo "usage: $0 <interface> [2nd interface]"
        exit 1
fi
#CORES=$((`cat /proc/cpuinfo | grep processor | tail -1 | awk '{print $3}'`+1)) ? it was getting the number of cores in our case 16
CORES=4 ? I hanged it to 4 to use 4 first cores 
hop=2
if [ -z $2 ]; then
        limit_1=$((2**CORES))
        echo "---------------------------------------"
        echo "Optimizing IRQs for Single port traffic"
        echo "---------------------------------------"
else
        echo "-------------------------------------"
        echo "Optimizing IRQs for Dual port traffic"
        echo "-------------------------------------"
        limit_1=$(( 2**$((CORES/2)) )) ? here it is calculating core limit so it gives 4 now
        limit_2=$((2**CORES))
        IRQS_2=$(cat /proc/interrupts | grep $2 | awk '{print $1}' | sed 's/://')
fi
IRQS_1=$(cat /proc/interrupts | grep $1 | awk '{print $1}' | sed 's/://')
if [ -z "$IRQS_1" ] ; then
        echo No IRQs found for $1.
else
        echo Discovered irqs for $1: $IRQS_1
        mask=1 ; for IRQ in $IRQS_1 ; do echo Assign irq $IRQ mask 0x$(printf "%x" $mask) ; echo $(printf "%x" $mask) > /proc/irq/$IRQ/smp_affinity ; mask=$(( mask * $hop)) ; if [ $mask -ge $limit_1 ] ; then mask=1; fi ;done ? in for loop it creates mask and multiplies by 2 with each iteration, then check if mask >= limit_1 (which is 4)
fi
echo
if [ "$2" != "" ]; then
        if [ -z "$IRQS_2" ]; then
                echo No IRQs found for $1.
        else
                echo Discovered irqs for $2: $IRQS_2
                mask=$limit_1 ; for IRQ in $IRQS_2 ; do echo Assign irq $IRQ mask 0x$(printf "%x" $mask) ; echo $(printf "%x" $mask) > /proc/irq/$IRQ/smp_affinity ; mask=$(( mask * $hop)) ; if [ $mask -ge $limit_2 ] ; then mask=$limit_1 ; fi ;done
        fi
fi
echo
echo done.
Generating superbook entries in platform.cgc/rdc from wadmin superbook status command
wadmin superbook status | sort | awk '{printf "%s:%s:%s:%s:%s\n","superbook", "platform", $2, $3, substr($4, 1, index($4, "(") - 1)}'
================================================================================================
WINDOWS CMD
tasklist - list processes
taskkill /IM PUTTY* /F - kill multiple processes
systeminfo| find "System Up Time" - PC up time.
grep "06:51:01\.[0-9][0-9][0-9],.*subscribeSecurity" \\LC18-CDFH06\lava\log\XLON_FH301.log | find /c /v "~~~" - counting lines in windows
=================================================================================================
EQLSE* ACCESS ##############################
eqlse1,2,3,4p access from jump servers: eqctic32p/41p/2d
-----------------------------------------------------------
Solaris:
gzip -d - unpack .gz
tar xvf - unpack .tar
%s/^\s\+// - delete white spaces on the begining of the line
%s/\s\+$// - delete white spaces on the end of the line
UTP:
grep Retransmission utp.log | wc -l
strings eurexebs_2.17.61g | grep -i "APPNAMESTR:  Version"
SSH KEY - FINGERPRINT
Public key problem: ssh-keygen --delete-host-id 194.169.8.40#58101 - to delete public key for specific host.
Display Fingerprints:
ssh-keygen -F /etc/ssh/ssh_host_rsa_key.pub
ssh-keygen -F /etc/ssh/ssh_host_dsa_key.pub
ssh-keygen -F /etc/ssh/ssh_host_key.pub
Display Keys:
cat /home/gmdemea/.ssh/id_rsa.pub
cat /etc/ssh/ssh_host_rsa_key.pub
cat /etc/ssh/ssh_host_dsa_key.pub
cat /etc/ssh/ssh_host_key.pub
Find and remove files older than:
find <path to directory from where remove> -type f -mtime +3 -exec rm {} \;
GENERATE, CONVERT, ADD KEYS:
Small corrections on second and third item. 
2A.         On each below listed kdb servers with “kdb” fid -> obtain public key in SSH tectia format.
2B.          On uk1pgmd01 or 02 – convert tectia_keys to openssh_keys, following command will be run for each key (by prod support team ) :
ssh-keygen -i -f tectia_key.pub > openssh_key.pub
3            Each openssh_key.pub will be appended to ~FID/authorized_keys on uk1pgmd01.prod.lava  and uk2pgmd01.prod.lava. 
Example for gmdemea  user (by GMD or support team)
cat openssh_key.pub >> ~gmdemea/authorized_keys
------------------------------------
######### NYSE SFTP:
sftp -P 1693 citiemea@euAppWebProxy.wlb.eur.nsroot.net
Pw: (jozPudd
Download website:
downloads.wombatfs.com
user:citiemea
pass:fQxGS1
-----------------------------------------------------------
Core file backtrace:
Copy corefile and binary to eqctic2d:/var/tmp (or somewhere)
gdb "binary" "corefile"
thread apply all bt
Copy output into file and add to WIM
------------------------------------
Morning Checks: ##################################
/home/pp72492/wad.sh /home/pp72492/wad.lst
---------------------------------------------
 ps command - Find if feed running: ####################################
ps -ef | grep <feed name>
ex: ps -ef | grep xetraebs

Find long running processes:
ps -eo etime,pid,comm,lstart,user,args | grep "^ [0-9]*-"
where etime -  ELAPSED  elapsed time since the process was started, in the form [[dd-]hh:]mm:ss.
For specific user:
ps -u gmdemea -o etime,pid,comm,lstart,user,args | grep "^ [0-9]*-" | sort -n
-------------------------------------
To find what feeds are running:
ps -ef | grep cticker or ps -ef | grep .*--name.* : shows only feeds
-------------------------------------
Stop Feed: ####################################
Kill command:
Kill -9 <proccess ID> - kills imediately
Kill <process ID> - kills gently (allowe to closeing procedures)
kill -3 <proccess ID> - creates coredump 
-------------------------------------
Start feed: #######################################
/opt/cticker/feedhandlers - . profile.wombat
/opt/cticker/feedhandlers - xetraebs --name=xetraebs &
xetraebs --name=xetraebs --input=/opt/loghome/cticker/playbacks/xetraebs.20100629.pb.gz --rewind --rate=1000 & - playback
rdf --name=rdf_p --input=/opt/loghome/cticker/playbacks/rdf.20130402.pb.gz --rate=1000 &
Playback recording ...
    <Parameter>
     <Name>ExtractFile</Name>
     <Value>/opt/loghome/cticker/playbacks/vienna.%Y%m%d.pb</Value>
     <Comment>Temporary measure to record playback during change freeze.</Comment>
    </Parameter>
----------------
Feedhendler Scripts: ################################
/opt/cticker/scripts
 - stopfh.sh <feed name> or stop.sh <feed name>
 - start.sh <feed name> <feed name_p/s>
 Start from playback file:
 ./start.sh utpcasheuro utpcasheuro_p -p  (-p -> play from playback - it takes a playback file from
	'/opt/loghome/cticker/playbacks/pblist where playbacks are specified. You can also use -p <playback file name>)
  ------------------------------------
  Autoweb server ##########################
  Logi in:
  cd /opt/autosys/autouser
  ksh
. ./autosys.ksh.euautocgcw11.P01 - prod 
. ./autosys.ksh.euautocgcw11.S01 - ua
. ./autosys.ksh.euautocgcw11.T01 - dev
. ./autosys.ksh.euautocgcw11.D01 - reporting
euautordcw12 - rdc backup server
  
GMD server:
  tiawccap001rdq 
Source:
  . /opt/CA/WorkloadAutomationAE/aliases
Type: QE2 - for QA
  
  Exporting jobs to a file:
  jd 156015% > /var/tmp/pp72492/jil_SUPPORT.txt
  
 Importing jobs:
 Suppotr, Dev:
 jil < /home/pp72492/x.txt
 
 delete_job: 156015_Support_monitor_5d_Start_b
 UA:
 create an update .jil file and copy to /opt/autosys/S01_JILS/ it will automatically process (every 20 min) 
 and send confirmation email
 
 ICE jobs
jd - description
jr - status 
joi - puts a job on ice s
foij - releases it back. 
fkj - full kill job
jsu - success job
fsj job_name #starts immediately job job_name
fkj job_name #kills the job job_name
jsu job_name #marks the job as success
Create Calendar:
http://www.exploreluxury.com/EL_Autosys/index.php?n=Autosys.Command-autocalAsc
1. Create file e.g. dates.txt in format:
calendar: Name_Of_Calendar
MM/DD/YYY
MM/DD/YYY
.
.
.
2. Log on to autosys instance e.g. DE2
3. Run: autocal_asc -I dates.txt - to import calendar
4. Check if it was created:
run autocal_asc
select: [1] Administer Standard Calendar
Select: [6] List all Standard Calendars.
select: [5] List dates for a Calendar.
put name of your calendar and it should display the dates on which job will be run.
Create job with: run_calendar: Name_Of_Calendar e.g.:
insert_job: 156015_MonthlyCapacityVolumesReport_Box_DEV    job_type: box
owner: cticker
permission: gx,wx
max_run_alarm: 0
alarm_if_fail: n
date_conditions: y
run_calendar: 156015_MonthlyCapacityVolumes
start_times: "09:00"
---------------------------------------------------
NEW AUTOSYS
tiawccap001rdq.eur.nsroot.net - primary
tiawccap002ffq.eur.nsroot.net - secondary
Ø	Autosys environment setup
•	After login:
•	. /opt/CA/WorkloadAutomationAE/aliases
•	DE2 - DEV and UA or 
•	QE2 - QA or
•	PE2 - PROD
•	tiawccap001rdq_DE2:
•	starting from here you can use jil interface as in 4.5
Basic test for the start:
Ø	Dump Job definition from R 4.5 environment
Ø	Move the definition to WCC1
Ø	Upload the definition to R11.3 
1. jr (job status) "job-name" 
2. jd (job definition) 
3 sendevent -E FORCE_STARTJOB -J "jobname" 
Force-start-job 
fsj job_name 
Output of full jil file 
jd 156015% >/home/db57575/jil.txt
Checks all jobs 
jr 156015% >/home/db57575/jobs-out2 
Add jobs to T01 
jil < 1.txt 
(pipe input from file into "jil") 
ICE jobs 
joi - puts a job on ice 
foij - releases it back. 
Intervention:
Force Start a Job:		fsj <JOBNAME> -C “YOUR COMMENT include your SOE ID”
Force Kill a Job: 		fkj <JOBNAME> -C “YOUR COMMENT include your SOE ID”
Manually Success a Job:	jsu <JOBNAME> -C “YOUR COMMENT include your SOE ID”
Find out more about these ...
term_run_time: 180
max_run_alarm: 180
alarm_if_fail: 0 or 1 
[db57575@uk1ptick01 ~]$ ps -ef | grep -i cybagent
db57575   7615  7254  0 11:42 pts/1    00:00:00 grep -i cybagent
root     11691     1  0 Jan25 ?        00:00:16 ./cybAgent.bin -a
root     11733     1  0 Jan25 ?        00:00:15 ./cybAgent.bin -a
 -------------------------------------
 Check if subscription hits mamacache:
 mamacache --name=mamacache_utp_p --mama-log-subsc-requests &
 
 -------------------------------------
 Bookviewer ##############################
 (eqctic2d:/home/db57575/Bookviewer - Duane's setup)
 
 cd /home/pp72492/Bookviewer/
 Superbook:
./bookviewer -W -L -tport worldview -dict_tport dict -Y SBCENTRIC -s bBNPP.PA -e
bookticker -W -L -tport worldview -dict_tport dict -Y SBCENTRIC -s bPTC.LS
bookticker -W -L -tport worldview -dict_tport dict -Y SBCENTRIC -s bCARR.PA | awk '{if (NF > 10) if($4 > $8) {print}}'
 
Direct subscription using bookviewer
./bookviewer -tport trqxitch -S TRQXITCH -s DK0010234467.DKK
Left site is a bid price, right is ask price. If bid price is graer than ask price it is a cross - we do 
superbook source resubscribe to fix it. Cross means that SB is too slow, if bid price is higher than ask
price it means that transaction should already occur.
 Bookticker - to see if we have crosses when source in SB / ST is disabled ####################
bookticker -W -L -tport worldview -dict_tport dict -Y SBCENTRIC -s dNESNvx.TQ
bookticker -tport rdf -S RDF -s bDNBNOR.OLd
mamalistenc -tport rdf -S RDF -s 0#G4S.CO - if cross on RDF_COPN use 0#[symbol] to refresh it
----------------------------------------
Resubscribe to one symbol only. #############################
Resubscribe to only one instrument on a Source
wadmin superbook orderBookResubscribe <Source Name> <ISIN.CURRENCY>
for example:
wadmin superbook orderBookResubscribe ENXBRUS_EB_EX  BE0003810273.EUR
------------------------------------------------------------------------------
TP21:
Get Tp21
35p - jumpbox
ssh eqcticXp and I am a cticker on eqcticXp
---------------------------------------------
WADMIN COMMANDS ###########################################
wadmin chix saveSymbolFile /var/tmp/chixSyms.sym symbolsOnly
wadmin chix saveOrderBookSymbolFile /var/tmp/chixOB.sym
wadmin feedname.hostname setLogLevel verbose on  - verbose mode
FORCE REFRESH Turquoiseitch
wadmin turquoiseitch.`hostname` sendTestRefreshRequest
Full Tollerant flip (ft flip)
  - wadmin worldview.eqctic5u setFtWeight 40
-----------------------------------------------------
CPU Usage LOG ########################################
On each box in /var/tmp/eqcticXX.process-stats.log.YYYMMDD
-------------------------------------------------------
----------------------------------------------------------
KDB queries: ############################################
UA:
http://eqkdb2u-vm:6044/?select from CTT
PROD:
http://eqkdbcgc4p:6044/?select from CTT

Security status per market:
eqkdbrdc3p:2006/statusPerMarket.scv?`ex xasc  select distinct ex, status from status where date within (2014.02.07,2014.03.07)

Count and sort - get most liquid stocks:
i is an invisible index that is there, counting it allows you to get the number of messages by sym.  
It defaults the column name to x so you can use `x xdesc on the front to get it descending (`x is the column bit)
Using trade table
http://eqkdbcgc1p:2014/?%60x%20xdesc%20select%20count%20i%20by%20sym%20from%20trade%20where%20ex=%60XWAR 
`x xdesc select count i by sym from trade where  ex=`XWAR
Using ebbo
http://eqkdbcgc1p:2014/?%60x%20xdesc%20select%20count%20i%20by%20sym%20from%20ebbo%20where%20%20%28bex%20like%20%22*XWAR*%22%29%20or%20%28aex%20like%20%22*XWAR*%22%29
`x xdesc select count i by sym from ebbo where  (bex like "*XWAR*") or (aex like "*XWAR*")

Checking latency between extime and gmdtime on KDB Tick Capture, greater than 100ms
select from ebbo where sym like "*.PA", time within (10:00, 10:20), 00:00:00.100<=(`time$gmdtime-`time$extime)
In Tick Capture client - gmdTime = tradeMsg.getMsgHdr().getAcqTimeStamp()
 

Check if no strange trade conditions:
http://eqkdbcgc1p:2014/?select%20from%20trade%20where%20%28not%20ttype%20like%20%22*Exch*%22%29%20and%20%28not%20ttype=%60OTC%29%20and%20%28not%20ttype=%60Other%29%20and%20%28not%20ttype%20like%20%22*Auction*%22%29%20and%20%28not%20ttype%20like%20%22*Auto*%22%29
select from trade where (not ttype like "*Exch*") and (not ttype=`OTC) and (not ttype=`Other) and (not ttype like "*Auction*") and (not ttype like "*Auto*")

Check stocks which did not open:
select from (select status by sym from status where ex=`XPAR) where not status like "*o"

Count instances of each trade condition:
select count i by ttype from trade where sym=`BNPP.PA, ex=`XPAR

KDB float format weirdness:
If using equal sign on numbers like ask=0 need to add 'e' like ask=0e

KDB query: select all Euronext stocks which start with status 'v' or 'f'
select from (select status, extime by sym from status where (ex=`XPAR) or (ex=`XAMS) or (ex=`XBRU) or (ex=`XLIS)) where (status like "v*") or  (status like "f*")

Timestamp difference between CGC and RDC - From Martin Mcgarvey - It has to run on the COB one because we have prod in the query
http://eqkdbrdc3p:2002/.csv?0!update diffTime:abs (extimePROD.time-extimeCOB.time) from (select extimeCOB:first extime by sym from trade where date=2016.01.06,ex=`XCSE,sym like "*.CO") lj (.dna.exec[`ARB.EMEA.EMEA_GMD_HIST:EMEA_PROD;"select extimePROD:first extime by sym from trade where date=2016.01.06,ex=`XCSE,sym like \"*.CO\" "])

Max Min Price:
select minPrice:min price,maxPrice:max price by sym from trade where date=2016.02.29, sym in `ZUMV.VI, time within (07:00,13:40)

Sum Trade size excluding off exchange and dark trades:
select sum size from trade where sym=`LLOY.L, execvenue=`OnExch,  not ttype like "ExchDark"

Calculate TotalVolume, DollarVolume and VWAP 
http://eqkdbrdc3p:2007/?update%20vwap:dVol%25tVol%20from%20update%20dVol:sums%20price*size,tVol:sums%20size%20from%20select%20from%20trade%20where%20date=2016.04.18,sym=`VOD.L,%20execvenue=`OnExch
update vwap:dVol%25tVol from update dVol:sums price*size,tVol:sums size from select from trade where date=2016.04.18,sym=`VOD.L, execvenue=`OnExch

Join Trade and uncross table for periodic auction:
{[d;s;e]`time xasc (update tbl:`trade from select date,time,sym,price,size,ex from trade where date=d, sym=s, ex=e, ttype=`EX_AUCTION_PERIODIC) uj update tbl:`uncross from select date,time,sym,ex,price:uncross_price,size:uncross_volume from uncross where date=d, sym=s, uncross_pricevar="P"}[2018.01.19;`ERICb.ST;`XSTO]

Login:
u: cititicker
p: tiger99
#### CGC - Real-Time ####
Quotes:
http://eqkdbap1p:5013/?select%20from%20CTquoteAg%20where%20sym=%60GB0001500809.GBX
http://eqkdbap1p:5013/?select%20from%20CTquote%20%20where%20sym=%60VOD.L
Trades:
http://eqkdbap1p:5013/?select%20from%20CTtradeAg%20where%20sym=%60GB0001500809.GBX
http://eqkdbap1p:5013/?select%20from%20CTtrade%20%20where%20sym=%60VOD.L
Quotes:
http://eqkdbap3p:5013/?select from CTquoteAg where sym=`GB0001500809.GBX
http://eqkdbap1p:5013/?select from CTquote  where sym=`VOD.L
Trades:
http://eqkdbap3p:5013/?select from CTtradeAg where sym=`GB0001500809.GBX
http://eqkdbap3p:5013/?select from CTtrade  where sym=`VOD.L
#### CGC - Historical ####
Quotes:
http://eqkdbap2p:9013/?select%20from%20CTquoteAg%20where%20date=2009.06.05,%20sym=%60GB0001500809.GBX
http://eqkdbap2p:9013/?select%20from%20CTquote%20where%20date=2009.06.05,%20sym=%60VOD.L
Trades:
http://eqkdbap2p:9013/?select%20from%20CTtradeAg%20where%20date=2009.06.05,%20sym=%60GB0001500809.GBX
http://eqkdbap2p:9013/?select%20from%20CTtrade%20where%20date=2009.06.05,%20sym=%60VOD.L
#### RDC - Historical #### - When querying historical always put date (time also makes it faster and les expensive) condition as a first after where clause!!!
Quotes:
http://eqkdbap4p:9013/?select from CTquoteAg where date=2012.03.07, sym=`GB0001500809.GBX, time within(11:00,12:15)
http://eqkdbap4p:9013/?select from CTquote where date=2012.03.07, sym=`VOD.L
Trades:
http://eqkdbap4p:9013/?select from CTtradeAg where date=2012.03.07, sym=`GB0001500809.GBX
http://eqkdbap4p:9013/?select from CTtrade where date=2012.03.07, sym=`VOD.L
Sec Status
http://eqkdbap4p:9013/?select from CTstatus where date=2012.03.07, sym=`POLV.VI, time within(11:00,11:15)
#### Turquoise crosses in SuperBook: ####
 
http://eqkdbap3p:5013/?select%20from%20CTquoteAg%20where%20bid>ask,ask>0,(bex%20like%20"*TQ*")%20or%20aex%20like%20"*TQ*"
http://eqkdbap3p:5013/?select from CTquoteAg where bid>ask,ask>0,(bex like "*TQ*") or aex like "*TQ*"
#### With ISIN's: ####
 
http://eqkdbap3p:5013/?select%20by%20sym%20from%20CTquoteAg%20where%20bid>ask,ask>0,(bex%20like%20"*TQ*")%20or%20aex%20like%20"*TQ*"
-----------------------------------------
#### CTquote: ####
RDC: http://eqkdb3p:5013/?select%20from%20CTquote%20where%20sym=%60POLYP.L,time%3E12:32
CGC: http://eqkdb1p:5013/?select%20from%20CTquote%20where%20sym=%60POLYP.L,time%3E12:32
#############################################
READING LOGS
permanently missed
RETRANS:
RetransRequest
Request Accepted
RetransResponse
End-of-File or server closed connection
RECOVERY:
trySendSnapshotRequest
Recovery): logged on successfully
SNAPSHOT:
snapshot complete
GAP (batseuropemc):
received seqnum gap
############# Notify about cticker servers outages
*EQ EU ATD
Vladimir Tokarev [ICG-MKTS]
===============================================================================================================
SQLCMD:
"C:\Users\pp72492>"C:\Program Files\Microsoft SQL Server\90\Tools\binn\"sqlcmd -S lr16-srvr06  -d EMEAAppDB -q "select * from SecurityMaster where RICcode = 'VOD.L'"
sqlcmd -S LR18-APPDBSQ01\lavaappdb01  -d EMEAAppDB -q "select * from SecurityMaster where RICcode = 'VOD.L'"
===============================================================================================================
MDLatency
run in: D:\LAVA\bin\EMEACD\MDLatency
Starting MDLatency tool for ColorData
java -Dconfig.home=D:\Lava\Bin\EMEACD\MDLatency\config -Djava.util.logging.config.file=D:\Lava\Bin\EMEACD\MDLatency\config\logging.properties -Dinstance=colordata -cp lib/MDLatency.jar;lib\CDI_SDK_v3.9.4.jar;lib\commons-logging.jar;lib\jdom.jar;lib\log4j-1.2.15.jar;lib\mamajni.jar;lib\mamda.jar;lib\mamda_book.jar;lib\mamda_options.jar;lib\quantum.jar;lib\spring.jar;lib\sqljdbc4-2.5p1.jar;lib\xerces.jar;lib\MDLatency.jar com.lava.latency.lifecycle.LifeCycleManager CDLatencyContext.xml
(-D system properties, -cp classpath search - specifu path to each .jar, main class, arguments)
Starting MDLatency tool for CitiTicker
java -Dconfig.home=D:\Lava\Bin\EMEACD\MDLatency\config -Djava.util.logging.config.file=D:\Lava\Bin\EMEACD\MDLatency\config\logging.properties -Dinstance=cititicker -cp lib/MDLatency.jar;lib\CDI_SDK_v3.9.4.jar;lib\commons-logging.jar;lib\jdom.jar;lib\log4j-1.2.15.jar;lib\mamajni.jar;lib\mamda.jar;lib\mamda_book.jar;lib\mamda_options.jar;lib\quantum.jar;lib\spring.jar;lib\sqljdbc4-2.5p1.jar;lib\xerces.jar;lib\MDLatency.jar com.lava.latency.lifecycle.LifeCycleManager CTLatencyContext.xml
===============================================================================================================
Config options
Tag = EnableTradePerMC - to get correct Service per market in CDIViewer 
===============================================================================================================
Ref Data (Brian Flannagan) #####################
Programs/ClientDesktopDeploymentTool/Ua/EMMA v1.3_D39
 - Select Envirment: LN Production
	- Product Service
		- Search
			- Search by AlternateId
				- AlternateId Type = REUT
				- AlternateId = RIC
				
================================================================================================================
Remote Desktop:
mstsc /span
===================================================================================================================
ATD new sftp (wilbur)
sftp emeaftp@uk-pt04.uk.atdesk.com
====================================================================================================================
Mamaperf stats:
Getting max latency greater than 50
awk 'BEGIN {FS=","}/SUPERBOOK.TOTAL_TO_CLIENT/ {if($8 > 50) print $2, $8;}' 20110831.wmw.superbook_c.stats.csv.2
=================================================================================================================
SAR ARCHIVE
Sar archive: /var/(adm/log)/sa/
- get Rx/TX drop packets or errors per sec:
sar -f /var/log/sa/sa15 -s 00:00:00 -e 23:59:59 -n EDEV | awk '{if ($4 > 0 || $5 > 0 || $7 > 0 || $8 > 0){print}}'
==========================================================================================================================
DART
user: administrator
pass: administrator
---------------------------------------
RESTORE london.xml ######
This is also in:
https://www.citi.net/confluence/display/156015/DART+Entitlements
under DART Failover – IMPORTANT section in RED bold
The siteserver will use a flat file called London.xml (encrypted) stored in /opt/cticker/dart/siteserver/config. on eqctic35p
A back up of this file is stored in /opt/loghiome/cticker/archive every day, so if it becomes corrupt we can copy a back up to the current location in the
siteserver config folder.
We monitor the siteserver logfile to make sure this London.xml is correctly downloaded every morning.
CT team will receive an email :
DART checks 2012-01-19 -- All OK
Dart Entitlement Checks Ok
If there is an issue downloading London.xml, this is  CRITICAL issue, Offshore/EGAS and CT will receive email:
DART checks 2012-01-19 - ERROR CONTACT CITITICKER DEV
 DART Fault:
 Issue with London.xml
 No Entitlements Downloaded
 Please Restore London.xml from Archive folder and bounce siteserver on eqctic35p
 Primary Contact: Jonathan White 07595943077
 Secondary Contact: Gregg O'Hara 07704065069
INSTRUCTIONS: In this case you need to log on to eqctic35p.
(1) cd /opt/loghome/cticker/archive
(2) Look for London.xml with date timestamp of yesterday.
(3) rename it to London.xml
(4) mv it to /opt/cticker/dart/siteserver/config
(5) then Restart siteserver:
ps -ef | grep siteserver - kill PID -9
/opt/cticker/scripts/DART_siteserver_start.sh
(6) You should then recieve an email saying DART checks ok
 
=================================================================================================================================
CTICDB
ICE superbooks:
sqlite /opt/cticker/scripts/cticdb.db "update cache set jbStatus = 'ICE' where cName like 'SB_C%' and cDCenter = 'CGC' and cFT = 'Secondary';"
==============================================================================================================================
ULTRAMAP RERUN and SB/ST/WV restart
ULTRAMAP START:
/opt/cticker/scripts/start_ultramap.sh
- on SB, ST, Worldview servers. (Or on WV servers, ST and SB instance on which the stock is.)
WORLDVIEW:
/opt/cticker/scripts/start.sh worldview worldview_p &
SUPERBOOK:
/opt/cticker/scripts/start.sh superbook superbook_a_p &
SUPERTRADE:
/opt/cticker/scripts/start.sh supertrade supertrade_p &
================================================================================================================================
SRLAB, Wombat linux developement environments
uk1ptick01
SMDS
/opt/cticker/smds/md-test
see the Makefile, you can specify one or all example utilities to recompile, if you want to make a code change
usage:
make mdsub –C /opt/cticker/smds/md-test
MAMA/MAMDA
haven’t go this working yet
mama
/home/cticker/
make examples/mama/mamalistenc -C .
===================================================================================================================================
EQ-CHANGE JIRA:
http://eqsupport1.nam.nsroot.net:8090/browse/EQC-1173
====================================================================================================================================
SCAN Subscription log and check difference between wSracTime and wLineTime
awk 'BEGIN {FS="."}/wSrc|wLine/ {if($1 ~ "wSrcTime.*") {printf "%s,%s,", $1, $2} else {printf "%s, %s\n", $1, $2}}' CHIX-sub.20120208.log > /var/tmp/wSrc-wLine.txt
awk 'BEGIN {FS=","}{ line=substr($4,0,4); src=$2 + 500; if(line + 0 > src + 0 ) {print;}}' /var/tmp/wSrc-wLine.txt | more
==========================================================================================================
Get msg/sec from feed log
 awk '/(Wimp \||statistics:)/ {if($4 == "Wimp"){printf "%s, ", $3} else{printf "%s\n", $0}}' utp.log > /var/tmp/utpRDCMsgSec.txt
 
=========================================================================================================================
SRLabs
MOreader
./mdmoreader -f euronext -m /opt/gmdemea/ref_files/utp_ref.mo -d > /var/tmp/euronext.txt
Ticketing system:
http://www.srtechlabs.com/index.php?option=com_content&task=view&id=16&Itemid=35
login: citi_user 
passwd : citi_smds
SRLABS ftp
Eqctic2d:/var/tmp
srlabs_ftp.sh
ftp -n hadrian.eu.ssmb.com
echo quote USER citiguest@dev.srtechlabs.com
echo quote PASS citi_guest
echo passive
echo bin
echo hash
SRLABS (Vela) NEW FTP:
•         Http Site - https://sr.brickftp.com/sessions/new
PROXY connection: sftp -o port=2464 citiguest@euAppWebProxy.wlb.eur.nsroot.net
Password: Srlabs@guest123
•         FTP Server - clientftp.srtechlabs.com
•         User - citiguest
•         Password - Srlabs@guest123
Vela SFTP HTTP:
https://sr.brickftp.com/
GMD SFTP NY:
sft-ny4p.prod.lava
SRLabs admin
/opt/gmdemea/smds/bin/admc -u gmdemea -h $1 -p $2 -c "$cmd"
Embedded eurex on uk1qgmd01:
/opt/gmdemea/smds/bin/admc -u gmdemea -h 169.182.163.52 -p 8031
SMDS Admin admc console testing
Open/Close
updatecustom CF_OPEN_PRICE 1 D SE0000242455.SEK.XSTO
updatecustom CF_CLOSE_PRICE 9 D SE0000242455.SEK.XSTO
Imbalance
updatecustom CF_AUCTION_VOLUME 1 S SE0000242455.SEK.XSTO
updatecustom CF_AUCTION_IMB_VOLUME 1 U SE0000242455.SEK.XSTO
updatecustom CF_AUCTION_PRICE_IND I S SE0000242455.SEK.XSTO
updatecustom CF_AUCTION_PRICE 100000 D SE0000242455.SEK.XSTO
Security Status:
smds#dev p xpar updatetradestatus MKT_AUCTION_SURPLUS FR0000131104.EUR.XPAR
MKT_AUCTION_CLOSE
MKT_CLOSE
Imbalance Message fields across apps. (Vela provides it on onCustom call-back)
SMDS					QBUS/BinaryProtocol			CDI
CF_AUCTION_IMB_VOLUME	imbalance_volume			Imbalance	--> Not populated on UTP but populated for Optiq
CF_AUCTION_SIDE			imbalance_side				Side			--> Not Used 
CF_AUCTION_PRICE		current_reference_price		Price		
CF_AUCTION_VOLUME		matched_volume				Volume
CF_AUCTION_PRICE_IND	cross_type					Type (Indicative/Firm)
Splitting SRLabs feed by symbol range:
You can specify supported-name-range on the MDConnection and we will ignore symbols out of this range.
Printing out Eurex Reference Data:
bin/mdsub -l /opt/gmdemea/smds/md-feed-config/ -c eurex.xml -a -f eurexRefData.csv -R
Subscribing with mdsub:
/opt/gmdemea/smds/bin/mdsub -l /opt/gmdemea/smds/md-feed-config/ -c xice-mdsub-conf.xml -u -a -f- -S "I FMU0019-I FMU0020"
Wildcard mdsub
/opt/gmdemea/smds/bin/mdsub -l /opt/gmdemea/smds/md-feed-config/ -c swxmdi_xvtx.xml -a -u -f- -S*
It is running on uk1pgmd02:
# Print out Eurex Ref Data
45 04 * * 1-5 /bin/bash /opt/gmdemea/scripts/eurex-RefData.sh
50 04 * * 1-5 /bin/bash /opt/gmdemea/scripts/eurex-RefData-stop.sh

SRLabs / vela log checks
line created
Sent login request
Login response
login successful
Recvd snapshot Final
Snapshot disconnected

==========================================================================================================================
ATD Server QBUS dev
putty ? cticker@169.182.164.105, pass cticker
then ssh cticker@uk-q17a, pass cticker
cticker@uk-q20a
then go to :
/opt/cticker/dev
source: env.sh
to compile: make
to run
./bookbuilder
----------------------------------------
ATD PROD Servers
uk-q20a,17a,18a,19a,27b,28b,29b (uk.atdesk.com)
The sudo su to atd should work, use your prod.lava access details
GMD Subscriber on uk2pgmd01:
source /opt/gmdemea/tools/env.sh
/opt/gmdemea/tools/src/gmd/gmd_subscriber
ATD configs:
/opt/gmdemea/tools/config/cgc/gmd_types/atdserver/gmd_message/
EX:
/opt/gmdemea/tools/src/gmd/gmd_subscriber -c /opt/gmdemea/tools/config/cgc/gmd_types/atdserver/gmd_message/xlon_gmd.cfg -s AZN.L
----------------------------------------
COBRA
uk-q19a.uk.atdesk.com - RDC
uk-q28b.uk.atdesk.com - CGC
lnp-thor03a - RDC
lnp-cobra05/06b - CGC 
Try qBus version:
/yum/qbus/rhel6_64/unofficial/our_packages
on newjob
ATD-qbus-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-kdb-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-gmd-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-exegy-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-dds-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-dbg-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-wombat-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-srlabs-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-rti-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-rfa-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-redline-0.34-0.1421328110.el6.x86_64.rpm
ATD-qbus-lbm-0.34-0.1421328110.el6.x86_64.rpm
COBTA/THOR UAT/QA runs on uk1qgmd02 GDS level_A,B,C,D
TCP test client:
/opt/gmdemea/tools/src/gmd_tcp/gmd_subscriber_tcp -c /opt/gmdemea/tools/config/gmd_tcp/xlon_tcp.cfg -s BVIC.L
TCP - Binary - GMDS level_A,B,C,D 
Client which requests snapshot (like Cobra / Thor clients)
uk1qgmd01
/opt/gmdemea/tools/bin/gmd/CobraThor_withSnapshot
./gmd_subscriber -c /opt/gmdemea/tools/config/rdc/gmd_types/atdserver/gmd_message/xlon_gmd.cfg -s BP.L
Test Subscribtion:
Subscribe for snapshot like Cobra:
On Servers: uk1qgmd01, uk2pgmd01:
source /opt/gmdemea/tools/env.sh
(gmd_subscriber - modified to request snapshot same way as Cobra / Thor)
/opt/gmdemea/tools/bin/gmd/CobraThor_withSnapshot/gmd_subscriber -c /opt/gmdemea/tools/config/cgc/gmd_types/atdserver/gmd_message/xosl_gmd.cfg -s DNB.OL

source /opt/gmdemea/tools/env.sh
RDC:
/opt/gmdemea/tools/src/gmd/gmd_direct_subscriber -c /opt/gmdemea/tools/config/rdc/gmd_types/atdserver/gmd_message/xlon_gmd.cfg -s LLOY.L
CGC:
/opt/gmdemea/tools/src/gmd/gmd_direct_subscriber -c /opt/gmdemea/tools/config/cgc/gmd_types/atdserver/gmd_message/xlon_gmd.cfg -s LLOY.L
Config LBM:
.feed_id 22
.plugin lbm
.section symbol-lists
0-G=/^[0-9A-Ga-g].*/
H-R=/^[H-Rh-r].*/
S-Z=/^[S-Zs-z].*/
ALL=/^[0-9A-Za-z].*/
.section lbm
lbm_xml_config_file=/opt/gmdemea/tools/config/lbm/receiver.xml
lbm_xml_file_appname=gmd
context_name=gmd
.section _Subscription_Request
partition=none
topic_name=SNAP_ATDSERVER_B
serialization_format=GMDS
profile=receiver
internal_batching=false
network_data=multicast://239.130.99.01:4001/ALL
.section _GMD_Message
partition=none
topic_name=ATDSERVER_XLON
serialization_format=GMDS
profile=receiver
internal_batching=false
network_data=multicast://239.130.100.73:4073/ALL
.msg_and_plugin_type _Subscription_Request Subscription_Request lbm
.msg_and_plugin_type _GMD_Message GMD_Message lbm
Config TCP:
[gmdemea@uk1qgmd02 gmd_tcp]$ cat xetr_tcp.cfg
.feed_id 27
.plugin GMD
.section _GMD_Message
plugin=GMD
parser=Regnms_Message_Parser
subscribe_user=bilge
subscribe_pass=bilge
subscribe_host=169.182.163.54
subscribe_port=14004
Feed_Id=27
Market_Center_Id=27
.msg_and_plugin_type _GMD_Message GMD_Message GMD
----------------------------------------
NX client (ATD remote desktop)
NX client - uk-vm008.uk.atdesk.com
host: uk-vm008.uk.atdesk.com
user: pp72492
pass: pp72491
Redmine
piotr.panczyk@citi.com
M1chal0w1!
Redmine:
http://svn.atdesk.com:3000
Yum:
Newjob.atdesk.com/yum
-----------------------------------------
Access qbus source code - Build Qbus:
Jump box: NY4DCoe01.dev.sti  --> q068.atdesk.com
Pass: in outlook notes 
ssh q068.atdesk.com
You can check out qbus code using:
git clone git@svn.atdesk.com:qbus.git
git checkout -b feature/master_without_binary_trade_side origin/feature/master_without_binary_trade_side --> !!!!This is our branch we build of, always check it out!!!! 
To build RFA:
Goto plugin/rfa and bjam -qaj7
RFA FIDs:
RFA API Download: http://cw-mds22:8080/emea/mdsweb/RFA/RFA/
https://collaborate.citi.net/docs/DOC-199457 -- Getting Started with RFA C++ Edition
-----------------------------------------------------------------

BPOD, RFA, RMDS Imbalance fields:
IndicAuct            : REAL           3   : [7.38]
IndAucSize           : UINT           3   : [685886]


BPOD, RFA Bloomberg security status logic 
EMEA_GMD_Message_Processor.cpp
Fields:
StatSScSim "StatSScSim"    -11689 = BPOD_Simp_Inst_Status_FID
StatSScPBb "StatSScPBb"    -11688 = BPOD_Simp_Inst_Status_FID_Auc
AucType    "Auction Type"  -12107 = BPOD_Auction_type_FID

config flag: bloomberg_use_sec_status_exch_fid

Idea:
If bloomberg_use_sec_status_exch_fid = false
we only use BPOD_Simp_Inst_Status_FID
but if bloomberg_use_sec_status_exch_fid = true
than we will use BPOD_Simp_Inst_Status_FID + BPOD_Auction_type_FID
to get detailed auction types
but if we cannot determine auction type from there we will try to get it from:
BPOD_Simp_Inst_Status_FID_Auc

--------------------------------------------------------------------------------------

q068.atdesk.com:/home/pp72492/qbus/src/qbus/plugins/rfa/rfa_wrappers/FIDs.hpp
this is just a simple VM we can do dev work on.
But the build boxes for qbus rpm’s, we use:
q068.atdesk.com (RH6 64 bit) 
q067.atdesk.com (Suse 11 64 bit)
you have access to these user and pass is your soeid again.
you can only access the build boxes from the vm-008 slice
RPMs:
ATD-qbus-0.31-5.1392301217.el6.x86_64.rpm -- Core qbus
ATD-qbus-srlabs-0.31-5.1392301217.el6.x86_64.rpm -- srlabs
ATD-qbus-lbm-0.31-5.1392301217.el6.x86_64.rpm -- lbm
ATD-qbus-gmd-0.31-5.1392301217.el6.x86_64.rpm -- gmd
ATD-qbus-rfa-0.31-5.1392301217.el6.x86_64.rpm -- rfa
Go to uk-vm008:/var/tmp and pull RPMs from q068.  
Install RPMs:
rpm -Uvh --nodeps ATD-qbus-develop-*
===========================================================================================================================
SRLabs | Qbus | GMDServer
DEV - uk1dtick01.dev.sti, uk1dtick02.dev.sti
PROD - uk1pgmd01.prod.lava - 169.182.162.33 14001
Start mdpub of playback(start_srlab.sh):
/opt/cticker/smds/bin/mdpub -i eth2 -f /opt/cticker/playback/pitch-eur-mc-2013-03-06-4.0.3-record.pb -b 10
Start Qbus bridge(qbus_startlab.sh -f bats):
qbus_bridge -s /opt/cticker/smartmap_V2/maps/BATE_MTF_maps.csv --config-file /opt/cticker/qbus/config/bridge_bats.cfg -b bats_bridge
Start GMDServer:
/opt/cticker/gmdserver/bin/cdsmain -c /opt/cticker/gmdserver/config/cd_nlvls.cfg
mdump to qbus bridge part1:
/opt/cticker/utilities/mtools/x86_64/mdump 239.199.4.16 4016
Client connection:
16:53:25.423687:T(0x2d84cf0):utils/session/GMDTcpAcceptorSessionImpl.cpp(234):Notify:NewTcpServerForkedSession:H(29),Loc:169.182.163.81:4294954181,Rem:169.182.163.16:4132
16:53:25.477230:T(0x2d84cf0):client/GMDAbstractClient.hpp(58):Notify:latency stats calculation enabled
16:53:25.480092:T(0x2d84cf0):client/GMDConnOrientedClientMgr.cpp(183):Info:New Client Connection: H(29),Loc:169.182.163.81:4294954181,Rem:169.182.163.16:4132
16:53:25.481393:T(0x2d84cf0):client/GMDConnOrientedClientMgr.cpp(186):Notify:Started thread successfully for connectionH(29),Loc:169.182.163.81:4294954181,Rem:169.182.163.16:4132
16:53:25.498122:T(0x7f4a9c00ba40):client/GMDAbstractClient.cpp(638):Notify:User :LAVANOC2 Logged On(No LogOn/Auth Check) Session: H(29),Loc:169.182.163.81:4294954181,Rem:169.182.163.16:4132
============================================================================================================
GMD Server build boxes:
Jump box: NY4DCoe01.dev.sti (169.176.42.215) (ssh from uk1dgmd01 to jump box)
from there you can access:
ny3-ldev04.dev.sti - 10.128.13.74
ny3-ldev05.dev.sti - 10.128.13.75 - rpm build
ny111-llab06-1.dev.sti - 10.128.13.82
ny111-llab07-1.dev.sti - 10.128.13.83 - done checkout on this one (/opt/cds/pp72492).
ny111-llab08-1.dev.sti - 10.128.13.84
ssh q068.atdesk.com
-------------------------------------------------
Build GMD Server
Check-out code using SVN:
command “svn co https://teamforgesvn.nam.nsroot.net/svn/repos/gmd/nam/trunk”. 
To get SVN access, your SOEID need to be added into teamforge. Your SVN login id would be soeid/<SSO> password. 
For your day to day testing you need not to built RPM, its matter of copying lib & bin directory (cds/dist/bin).
To bump up the version
1)	You need to check out the gmd code from svn (under your username).
2) Update cdsverinfo file (nam/trunk/cds/buildinfo/cdsverinfo), increment version number by 1.
3) Get current svn revision number by running command 
	$ svn info (svn info https://teamforgesvn.nam.nsroot.net/svn/repos/gmd/nam/trunk/cds)
	[dc57278@ny111-llab06 cds]$ svn info
	Path: .
	URL: https://teamforgesvn.nam.nsroot.net/svn/repos/gmd/nam/trunk/cds
	................................
	................................
	Revision: 2482			--> This is current version number
	
4) Set version number in release notes (nam/trunk/cds/releasenotes/ReleaseNotes-GMD) as:
	- v<major version number>-<current SVN revision +1>
	- current revision number +1 (next svn check-in revision number)
	- So it will become like:
		v1.22-2483
	- Additionally it is good to have all SVN revision numbers in brackets after comments where that particular feature was checked-in, 
	  example:
	     1) GMD EMEA - Enhancement for encoding "Instrument Status" message
	        as FFLEX PassThru message, MsgId=1149 (Svn Rev no 2451, 2462) --> 2451 and 2462 are SVN revision number where I made code changes for this feature.
5) Check-in both files (cdsverinfo and ReleaseNotes-GMD) together:
   svn ci -m "log message" path_to_file _to_br_commited
6) generate RPM.
You need to become cdsdev to build rpm. Once you sudo as cdsdev
To build the rpm 
All you need to do is
Go to 
/opt/cds/cdsdev/ProdBuild/Gmd
Run update.sh
Run rpmbuild -bb rpm/SPECS/cds/cds.spec
This will build the rpm in /opt/cds/cdsdev/ProdBuild/RPMS/x86_64/
To install it
rpm –ivh –prefix=/opt/cds/cdsprod/bininstalls –nodeps <rpmname>
You can change the prefix to path of your choice.
Manually build GMDS:
go to cds folder (e.g. /opt/cds/dc57278/projects/gmd/nam/trunk/cds) and run command:
$ bjam --enable_plugins=srlabs
Copy libs (*.so) and cdsmain from following location:
/opt/cds/dc57278/projects/gmd/nam/trunk/cds/dist/bin/release
/opt/cds/dc57278/projects/gmd/nam/trunk/cds/dist/lib/release
---------------------------------------------------------------------------------------------------------
GMDS compile - GMD server
bjam -qj7 - q - stop on first error, j7 will create 7 threads
source /opt/cds/pp72492/.bashrc
GMDS Build on uk1dgmd01 - source /opt/loghome/teamForke/gmd/nam/trunk/cds/env.sh use Jamroot.jam.pp72492 (will be replaced after svn update) in /opt/loghome/teamForge/gmd/nam/trunk/cds
Debug GMDS:
From client subscription:
client/GMDAbstractClient.cpp:790 - bool GMDAbstractClient::handleSubReqClient(const GMDSubscription& sub)
For SuperBook snapshot - in:
symbolcache/GMDServerSymbolCache.cpp:1210 - bool GMDServerSymbolCache::buildAndSendStaticInfoSnapShot(
If adding new field remember to set it after staticInfo copy: *msg=m_staticInfo; --> this is copying only specific fields and new stuff is lost.
---------------------------------------------------------------------------------------------------------
GMDS install steps (relese):
cd /opt/gmdemea/versions/gmdserver_versions/
ls -l
tar -xzvf v1.48-3785.tar.gz
ls -l
rm v1.48-3785.tar.gz
ls -l v1.48-3785
cd /opt/gmdemea/
ls -l
rm gmdserver
ln -s /opt/gmdemea/versions/gmdserver_versions/v1.48-3785/ gmdserver
ls -l
ps -ef | grep cds
ps -ef | grep cds | grep -v grep | awk 'BEGIN {FS="-c"} {print $2}' | awk 'BEGIN {FS="/"} {print $6}'
kill `ps -ef | grep cds | grep -v grep | awk '{print $2}'`
ps -ef | grep cds
/opt/gmdemea/scripts/gmdserver_start.sh -f  
EMEA RPM install
Change path from:  /opt/cds/cdsprod/bininstalls/ to: /opt/gmdemea/versions/gmdserver_versions/
Add to build: 
env.sh,
symbolic link: ln -s /opt/gmdemea/config/gmdserver-config-current/ config
symbolic link: ln -s /opt/gmdemea/versions/gmdserver_versions/tools/ tools 
--------------------------------------------------------------------------------------------------------------
QBUS install steps:
cd /opt/gmdemea/versions/qbus_versions/
tar -xzvf qbus-0.32-13.1420174279.el6.tar.gz
cd qbus-0.32-13.1420174279.el6
cp ../qbus-0.32-11.1417160021.el6/env.sh .
ls -l
cd /opt/gmdemea/
rm qbus
ln -s /opt/gmdemea/versions/qbus_versions/qbus-0.32-13.1420174279.el6/ qbus
ls -l
crontab -l | grep "^[0-9].*qbus_start"
crontab -l | awk '/^[0-9].*qbus_start/ {print $7" "$8" "$9" "$10" "$11" "$12" "$13}'
crontab -l | awk '/^[0-9].*qbus_start/ {for (i=0;i<=NF;i++){if(i > 6){printf "%s ",$i}; if(i == NF){printf"\n"}}}'
crontab -l | awk '/^[0-9].*gmdserver_start/ {for (i=0;i<=NF;i++){if(i > 6){printf "%s ",$i}; if(i == NF){printf"\n"}}}'
Restore crontab file from cron log:
awk '/^2016-10-28.*gmdemea.*CMD/ {time=substr($1, index($1, "T")+1); split(time, time_arr, ":"); idx=(index($0, "(/bin/bash")+1); cmd=substr($0, idx); sub(/)/, "", cmd); print time_arr[2]" "time_arr[1]" * * 1-5 "cmd}' /var/tmp/cron-20161030
--------------------------------------------------------------------------------------------------------------
SRLabs install steps:
cd /opt/gmdemea/versions/srlab_versions/
tar -xzvf srlabs-4.0.7.56.tar.gz
cd srlabs-4.0.7.56
ls -l
cd /opt/gmdemea/
rm smds
ln -s /opt/gmdemea/versions/srlab_versions/srlabs-4.0.7.56/ smds
ls -l
rm -r v1.47-3569 v1.49-3901.tar.gz
ls -l
cd v1.49-3901
ls -l
----------------------------------------------------------------------------------------------------------------
GMDS install steps
cd /opt/gmdemea/versions/gmdserver_versions/
tar -xzvf v1.49-3901.tar.gz
rm -r v1.47-3569 v1.49-3901.tar.gz
ls -l
cd v1.49-3901
ls -l
=========================================================================================================
GMD Server configs
session.cfg --> msgprocessors.cfg --> decoder.cfg
session.cfg - topic is associated with FeedDataHandler --> ATD_XLON_CGC --> FeedDataHandler_1
msgprocessors.cfg - FeedDataHandler is associated with Decoder --> FeedDataHandler_1 --> CitiBinary_Decoder
decoder.cfg - decoder is associated with FeedId --> CitiBinary_Decoder=CitiBinary_ConfigSection_1 --> FeedId=XLON
So Topic ATD_XLON_CGC is associated with FeedId=XLON
FeedDataHandlerId(specifies feed if mcast split exist there will be separate ID for each split)=FeedDataHandler_1
E.X:
[RcvSession_ConfigSection_1]
SessionType=29WestReceiver
EventLoopId=Dummy
SessionCallBackId=FeedDataHandler_1
Topic=GMD_BATS:239.199.15.16:4016
MsgLengthFinderPlugInType=Dummy
[RcvSession_ConfigSection_2]
SessionType=29WestReceiver
EventLoopId=Dummy
SessionCallBackId=FeedDataHandler_2
Topic=GMD_BATS:239.199.15.17:4017
MsgLengthFinderPlugInType=Dummy
[RcvSession_ConfigSection_3]
SessionType=29WestReceiver
EventLoopId=Dummy
SessionCallBackId=FeedDataHandler_3
Topic=GMD_BATS:239.199.15.18:4018
MsgLengthFinderPlugInType=Dummy
==========================================================================================================
GMDS LOG Checks
FFLEX Price precision: 6DP 6 decimal places
Users:
grep "Notify:User:.* logged on" /opt/loghome/gmdemea/gmdserver/superbook_0G/GMDServer_0G.1.log | wc -l
Disconnected users:
grep "Info: Connection closed:" /opt/loghome/gmdemea/gmdserver/superbook_0G/GMDServer_0G.1.log
grep "Remote Socket Close:"
Client on specific thread + session ID:
grep "Notify:assigning client.*ClientFFLEX" GMDServer_0G_secondary.1.log
Subscritions:
grep "Notify:Subscription Request Received" /opt/loghome/gmdemea/gmdserver/superbook_0G/GMDServer_0G.1.log | wc -l
Number of subscriptions on specific session:
grep "Notify:Subscription Request Received.*session H(128)" GMDServer_0G_secondary.1.log
Unsubscription:
"Notify:Handling unsubscription request"
"Notify:Handling RemoveAllSubscription request"
"Notify:subscription not found for:"
"Notify:removing.*subscription for:"
Memory Allocationg:
grep "Allocating More in Pool" /opt/loghome/gmdemea/gmdserver/superbook_0G/GMDServer_0G.1.log
grep "Pool Size Explosion" /opt/loghome/gmdemea/gmdserver/superbook_0G/GMDServer_0G.1.log
Socket failed:
Notify:Write Failed on the Socket Pair
Unrecoverable message:
Error:Unrecoverable Message on topic
==========================================================================================================
Snapshot on windows CDS
1141|LAVANOC1|LIVE (18-4-28)|16|17|XLON|O|16|LSE Orderbook Feed|Y|N|CHIX|O|16|CHIX Orderbook Feed|Y|N|BATE|O|16|BATS Orderbook Feed|Y|N|XVTX|O|16|SWX Europe - VTIRX OrderBook Feed|Y|N|XETR|O|16|XETRA OrderBook Feed|Y|N|XAMS|O|16|Euronext Amsterdam OrderBook Feed|Y|N|XPAR|O|16|Euronext Paris OrderBook Feed|Y|N|TRQX|O|16|TRQX Orderbook Feed|Y|N|XHEL|O|16|OMX Helsinki OrderBook Feed|Y|N|XSTO|O|16|OMX Stockholm OrderBook Feed|Y|N|XBRU|O|16|Euronext Brussels OrderBook Feed|Y|N|RDF1|O|16|RDF Orderbook Feed|Y|N|XLIS|O|16|Euronext Lisbon OrderBook Feed|Y|N|MTAA|O|16|Borsa Italiana - MTAA OrderBook Feed|Y|N|XATH|O|16|ATHENS OrderBook Feed|Y|N|WBAH|O|16|Vienna OrderBook Feed|Y|N|MISX|O|16|MISX-RDF Orderbook Feed|Y|N|3|1|0|G|
1125|BT.L|062009692|O|  [  ]|XLON|L|N| | | | |0||0|||XLON|0|0|283.7|276.6||7.1|3121970|0|0|283.7||0|0|3121970|5|1|062009692|L|U|283.7|1553828|x:1009|OTC|OffExchange|GB|1|1|1|LAVA|9|062009692|O||||0|0||0|0|0|0|0|1|040030075|Q|XLON|XLON|L|p|||111|9999|1|061554397|XLON|||M|0|||0|0|0||||000000000|1|0|
1126|BT.L|062009692|0|0|S|
201|BT.L|062009692|LAVA|^C|^S|0|^L|||||||^T||0|0|
GMD Server
205|1|0|Z|2|BT01|O|1|BT01 Order A-Z|Y|N|GMDSERVEBT01 Order A-Z|O|1|BT01 Order A-Z|Y|N|
4|LAVANOC1|LIVE_(9-9-9)|15|1|1|0|Z|0|0|0|0|0|0|0|
200|BT.L|304327623|LAVA|^C|^T||0|0|
202|BT.L|304327623|LAVA|^C|^T||0|0|
204|BT.L|304327623|LAVA|^C|^T||0|0|
400|BT.L|304327623|O|BT.L||N| | | | |0|17||0||
=============================================================================================================
GMD TOOLS
GMD Client
Ny111-llab07:/home/ms89376/GMDClientAPI-1.0.2/GMDClientAPI-1.0.2-1.x86_64.rpm
Qbus Book Builder example app:
/opt/cticker/tools/src/gmd/qbus_book_builder -c /opt/cticker/tools/config/gmd/Direct_xlon.cfg -s VOD.L
qbus_book_builder.cpp
qbus_book_builder.hpp
GMD Direct Book
/opt/cticker/tools/src/gmd/gmd_direct_book -c /opt/cticker/tools/config/gmd/Direct_xlon.cfg -s VOD.L
Embeded book handler for GMD Direct Book bilding
/opt/cticker/tools/include/Embedded_Book_Handler.hpp
/opt/gmdemea/tools/src/gmd/gmd_bookticker -c config/rdc/gmd_types/atdserver/gmd_message/xetr_gmd.cfg -s RWEG_p.DE
Security Status handler
/opt/cticker/tools/include/GMD_Message_Sec_Status_Handler.hpp
GMD Direct Subscriber tool
/opt/cticker/tools/src/gmd/gmd_direct_subscriber -c /opt/cticker/tools/config/gmd/Direct_xlon.cfg -s VOD.L
Direct SRLabs subscription for VOD.L (using millenum code)
/opt/gmdemea/scripts/start_srlab.sh -f lse -s 6147 --> on uk1pgmd01.prod.lava
==============================================================================================================
GDB -read coredump
gdb /opt/cticker/tools/src/gmd/gmd_direct_book core.gmd_direct_book.1370342206.19181
backtrace -> stack
Find where coredump files are:
vi /etc/sysctl.conf
---------------------------------------------
GDB - run process
  gdb --args binary
  r -c config
OR
gdb --args binary and config arguments
start
c --> continue or breakpoints
Attach GDB to running process:
gdb --pid=53029
  
displays gdb prompt
type r - to run
c - continue
s - step into
n - next - step over
l - list - show source code
list [linenumber] - to see specific line
ctrl-c to stop and set breakpoints
Breakpoints:
break [filename]:[linenumber]
break [functionname] - break on function
b - breakpoint - ex.: b symbolcache/GMDServerSymbolCache.cpp:1236
    To list current breakpoints: "info break"
    To delete a breakpoint: "del [breakpointnumber]"
    To temporarily disable a breakpoint: "dis [breakpointnumber]"
    To enable a breakpoint: "en [breakpointnumber]"
    To ignore a breakpoint until it has been crossed x times:"ignore [breakpointnumber] [x]" 
Split gdb screen to see code command: layout
Switch between normal and split screen: Ctrl-x Ctrl-a
	
p - print variables
To print pointer: {type} addres ex.: p {GMDStaticInfoMsg} 0x2aaad13d2f18
====================================================================================================================
RFA client:
On uk1pgmd01.prod.lava
/opt/gmdemea/tools/scripts/run_rfa_client.sh
dIDN_SELECTFEED
RMDS Client:
/opt/gmdemea/tools/bin/rfa/rmdstestclient -u gmdemea -S BPOD  -f /opt/gmdemea/tools/RFA_sym_files/IDN.items -h rd-p2psa1.eur.nsroot.net   -ct rssl -X -d 3 -v
-S (source) - BPOD / IDN_RDF
-f (sym file) add symbols there
CDIT - Thomson Reuters testing service
RMDS service name=CDIT, on UAT servers: cwu-p2ps1.eur.nsroot.net, cwu-p2ps2.eur.nsroot.net
/opt/gmdemea/tools/bin/rfa/rmdstestclient -u gmdemea -S CDIT  -f /opt/gmdemea/tools/RFA_sym_files/IDN.items -h cwu-p2ps1.eur.nsroot.net   -ct rssl -X -d 3 -v
RFA bsym bloomberg level 2 symbol add ?mbl -> L1: syALPHA.GA -> L2: syALPHA?mbl.GA
RFA Reuters dictionary: /opt/gmdemea/rfa/etc/RDM/RDMFieldDictionary - to check fields we use from Reuters

Reuters RFA find level 2 symbol:
If you can provide a sample level 1 RIC for any of the markets I can double check but , 
this is generally the approach I follow if I can’t find a direct reference.
•         Take the level 1 RIC name
•         Reuters normally have a chain containing the level1 and level 2 quotes
•         In the case of 1MFXIX8, the chain is 0#MFXIX8 (ie: prepend with 0#, drop the leading 1 from the level 1 name)
•         LONGLINK1 and LONGLINK 2 (FID 800 and 801) give the names of the level 1 RIC and level 2 RICs: MFXIX8 and DMFXIX8
Normally within an exchange you can expect similar behaviour, but between exchanges there are definite variations.

====================================================================================================================
GMDS CLI support functionality
SuppressFeed/RemoveFeed
1.	After issuing any of these commands,  Client will receive quote messages to clear all the levels (basically Qty would be zero in this case).
2.	In SuppressFeed, GMD server will not clear its internal book and will keep building its book but will not send any further updates to the client.
After the feed is Unsuppressed, the GMD Server will start publishing the book.
3.	In Remove Feed, GMD server will clear its internal book and will discard any incoming messages from feed handler (e.g. from Qbus Bridge).
After the feed is added back, the GMD server will start building the book from scratch and publish the same.
Use cases:
Use case for SuppressFeed:
1.	Admin wants to temporarily stop publishing book of a particular feed from the GMD server.
2.	Admin will issue unSuppressFeed if he wants to start publishing the book again.
Use case for RemoveFeed:
1.	There is issue in incoming feedhandler  (e.g. Qbus Bridge) and Admin want to restart the feedHandler.
1.	There is issue in incoming feedhandler  (e.g. Qbus Bridge) and Admin want to restart the feedHandler.
So in this case GMD server expects that the Qbus Bridge should publish data from scratch before he issue AddFeed command.
Steps to execute the command:
                RemoveFeed/AddFeed:
•	Issue RemoveFeed command.
•	Stop Qbus bridge.
•	Issue AddFeed command.
•	Start the Qbus Bridge.
                SuppressFeed/UnsuppressFeed:
•	Issue SuppressFeed command.
•	Issue UnSuppressFeed command.
Note: Here you must not restart the Qbus bridge. The intention is to temporarily stop publishing book from GMD server.
Command:
DisconnectClient <user_name> - Wildcard not allowed in user name.
=======================================================================================================================
GMD Client API
Download location
Jump box: NY4DCoe01.dev.sti (169.176.42.215)
Location :  /opt/cds/GMDClientApi/GMDClientAPI-1.0.7
Server    :  ny3-ldev04.  
Subscription config:
The snippet of the symbol file is as follows –
Symbol, FeedName, MktCtrName, [ConflationFactor, KeepSubAlive, SubType]
Symbol,FeedName,MktCtrName, [ConflationFactor, KeepSubAlive, SubType]
AAPL,BatsPitch,BATS
AGOL,BatsPitch,BATS
AGA,BatsPitch,BATS
AGF,BatsPitch,BATS
ACWI,BatsPitch,BATS
AEG,BatsPitch,BATS
AIXG,BatsPitch,BATS
A,BatsPitch,BATS
KeepActive, KeepSubAlive : GMD will reject the subscription if at the time of subscription there exists no symbol cache, if rejected and later updates become 
available in GMD client will not get it. To make the updates available this flag needs to be set to 1
default value for  KeepSubAlive =1
SubType : is one of the GMD_CLIENT_SUBTYPE_NONE(0),GMD_CLIENT_SUBTYPE_SNAPSHOT(1),GMD_CLIENT_SUBTYPE_SNAPSHOTUPDATES(2),GMD_CLIENT_SUBTYPE_UPDATESONLY(3);
Default is GMD_CLIENT_SUBTYPE_SNAPSHOTUPDATES 
ConflationFactor : This is currently not used in GMD. but it will be used to later to provide throttling feature

GMDAPI binary dump decoder - GMDBinaryMsgDumpDecoder
#!/bin/bash

source /opt/gmdemea/client_java/config/cgc/primary/setupenv.sh

java -DAPI_LOG_HOME=$API_LOG_HOME -Dlog4j.configuration=file://${API_HOME}/config/cgc/primary/log4j.xml -classpath "$API_CLASSPATH" com.citi.gmd.client.utils.GMDBinaryMsgDumpDecoder /home/PP72492/CON3_Inbound_2018-01-11-05-10-02.dat CON3_LULD.txt &
echo "API started"

exit 0
=======================================================================================================================
ServiceNow, SN, Service Now:
GMD group: ICG EM AD GB EMEA MARKET DATA
ITRS changes group: EU OFFSHORE PROD SUPPORT
Expedite change template: CTMP0000001454
Planned change template: CTMP0000001711
=========================================================================================================================
GMD support:
Qbus QMD:
qmd -c /opt/gmdemea/qbus/config/qmd.cfg | grep PID
=========================================================================================================================
Smart DCA 
tcp 169.186.130.129:1030  10.154.172.97:40738   169.182.170.22:14001  169.182.170.22:14001
10.154.172.97 - eqtotap1lnp.eur.nsroot.net connects to CGC Primary
Address in GMDS log: 169.186.130.129 - used to translate from CTI IP to STI IP, somehow it shoes as client IP in the logs.
=========================================================================================================================
Regression in GMD
FFLEX client:
Trades
gawk '/^EquityTradeUpdate\|LLOY\.L/' CDIClientUpdates_p2.log | wc -l
gawk '/^EquityTradeUpdate\|LLOY\.L\|.*Auction/' CDIClientUpdates_p2.log | wc -l
gawk '/^EquityTradeRecap\|LLOY\.L/' CDIClientUpdates_p2.log
Orders
gawk '/^EquityLimitOrderUpdate\|LLOY\.L/' CDIClientUpdates_p2.log | wc -l
Quotes
gawk '/^EquityInsideUpdate\|LLOY\.L/' CDIClientUpdates_p2.log | wc -l
Imbalance
gawk '/^EquityImbalanceUpdate\|LLOY\.L/' CDIClientUpdates_p2.log | wc -l
Sec Status
gawk '/^EquityQuoteIndicatorUpdate\|LLOY\.L/' CDIClientUpdates_p2.log
========================================================================================================================
GMD EMEA TipOff
http://169.182.167.90/TipOff/ui/tipoff-login.php --> accessible through UK RDC NOC Box
admin/admin123
======================================================================================
SVN on uk1dgmd01.dev.sti
/opt/CollabNet_Subversion/bin
Checkout:
svn checkout --username pp72492 https://teamforge.nam.nsroot.net/svn/repos/gmd
========================================================================================
Ayub mobile: +447466396566
========================================================================================
LBM recording / replaying
lbmrcv_dump, lbmsrc_dump
Server: uk1qgmd02
Dir: /opt/gmdemea/scripts/LBMRecordingTool/
Recording start script:
/opt/gmdemea/scripts/LBMRecordingTool/29west/tools/lbmRecord_start.sh
Replay command:
./lbmsrc_dump -c cfgs/EMEA-UAT.cfg -P 5 -M 100000 -f lbmrcv_dump_XWAR_SZ_23092014.bin 'ATD_UAT_REPLAY_XWAR:239.199.4.153:4153'
==================================================================================================================================
Bloomberg Security status
So for security status on Bloomberg
Using Budapest as an example:
Uk1pgmd16: /opt/gmdemea/qbus/config/bridge_xbud.cfg
We use:
*.*.*.*.rfa.xbud.bloomberg_venue_eid=14116
*.*.*.*.rfa.xbud.instrument_status_map_file=/opt/gmdemea/qbus/config/rfa_sec_status_mapping.xml
*.*.*.*.rfa.xbud.trade_condition_map_file=/opt/gmdemea/qbus/config/rfa_trade_condition_mapping.xml
*.*.*.*.rfa.xbud.trade_condition_map_file_overwrite=/opt/gmdemea/qbus/config/rfa_trade_condition_mapping_XBUD.xml
The top of this file in comments shows the status we use from BBG:
<!--  --- BPOD Summary.Status.Security.Simplified - Normalised (StatSScSim, -11689) ---
- "NONE" - the current status of the security is undefined;
- "INEG" - the security is ineligible to trade, e.g. pending listing, delisted, private company, etc.;
- "CLOS" - the security has closed trading for the day;
- "TRAD" - the security is actively trading;
- "AUCT" - security is in an auction call phase;
- "TRAU" - the security is in continuous trading, with an auction call running in parallel;
- "HALT" - the security has been temporarily halted from trading;
- "HLTA" - the security is temporarily halted and is in an auction call phase;
- "SUSP" - the security is presently suspended from trading;
- "OUT" - the security is trading in an out-of-hours trading phase;
- "UNCR" - the security is presently in an auction uncrossing phase;
- "TALC" - the security is in a trade-at-last or trade-at-close trading phase; and
- "NOTR" - the security is not presently available for trading.
And we map from these enums to our GMD enums
i.e.
        <Map>
            <MapFrom>CLOS</MapFrom>
            <MapTo>c</MapTo>
        </Map>
This populates market_center_trading_status=[……] array in GMD message.
So BBG send BBG field Status.Security.Simplified which is mapped in the MFA (Feed Adaptor, BBG? Reuters FID converter) as Reuters FID (StatSScSim, -11689)
So when we see the notice for Budapest we can see we have new indicators:
PREO – PreOpen phase – do we need to have this?
ABAL (previously UNCR) – these have trading periods of opening, intraday and closing auctions – I think we are safe just to add new mapping of ABAL to auction gmd enum (a)
POST (previously TRAD) – do we need post trading flag?
As I see it its just one update to opt/gmdemea/qbus/config/rfa_sec_status_mapping.xml to include
       <Map>
            <MapFrom>ABAL</MapFrom>
            <MapTo>a</MapTo>
        </Map>
But this is common file, so we need to check in pre prod it doesn’t impact other BPOD feeds.
Also we should run the rmds test client in pre prod to see this new phase and its transitions (record sec status)
[gmdemea@uk1qgmd01 scripts]$ pwd
/opt/gmdemea/tools/scripts
./rmdstestclient -u gmd_emea -S BPOD  -f /opt/gmdemea/tools/RFA_sym_files/IDN.items -h rd-p2psa1.eur.nsroot.net   -ct rssl -X -d 3 –v
Where IDN.items is a Budapest stock: bysm: syBASF.BSE (level 1)
======================================================================================================================================
GMDS tunning:
Next Release:
Because we have only one GMDS running on the server maybe we could give 2 cores for IRQ’s and 6 for GMDS, additionally we could decrease FFLEX client threads to 2.
Does that sounds sensible?
Onload (recomended values):
export EF_INT_DRIVEN=1
export EF_POLL_USEC=100000 - user mode
export EF_PREFAULT_PACKETS=100000
Context switching:
grep ctxt /proc/<pid>/status --> Lots of context switching on 29WestReader thread
Checking onload config:
onload_fuser
onload_stackdump lots |grep poll
---- EFVI ----
EFVI requires c++ 11.  
1)	You can use the latest GCC-4.8.3 smds package available for compilation on ny111-llab07.
/home/sj38355/gcc-4.8.3-install/
2)	SR Labs build on ny111-llab07 with EFVI.
/opt/tools/installs/srlabs/srlabs-4.1.0.30
3)	Gcc 4.8.3 is compatible with boost 1.55 which can be found in below location in xenv.
/xenv/Boost/X/1.55.0/BINGRP_ia64
4)	Upgrading to boost1.55 and gcc 4.8.3 will require code changes in our code base.
You can refer to the code changes in the below directory on ny111-llab07. Jamroot.jam has also the changes to include Boost 1.55, gblibc2.14(pls exclude feed data handler changes, they are for skeleton)
/opt/cds/rn55679/gmds_4.8.3/gmds
Also please make sure to include the correct gcc libs, glibc2.14 and SR labs library in LD_LIBRARY_PATH and gcc 4.8.3 bin folder in PATH while running the application.
--------------------------------
Assigning cores in eventloop.cfg:
[EventLoop_Config]
EventLoop_SymCacheMgr=EventLoop_SymCacheMgr_ConfigSection
EventLoop_ClientMgrFFLEX=EventLoop_ClientMgrFFLEX_ConfigSection
EventLoop_ClientMgrBinary=EventLoop_ClientMgrBinary_ConfigSection
EventLoop_AdminClientMgr=EventLoop_AdminClientMgr_ConfigSection
# RFAProvider (1)
EventLoop_RFAClientMgr=EventLoop_RFAClientMgr_ConfigSection
[EventLoop_SymCacheMgr_ConfigSection]
EventLoopPlugInImplType=IntObj
PoolMgrInitializer=SymCacheManagerPool
QueueSize=1000000
CallBackArraySize=1000
CoreId=8
[EventLoop_ClientMgrFFLEX_ConfigSection]
EventLoopPlugInImplType=Network
PoolMgrInitializer=ClientMgrInstPool
CoreId=9
[EventLoop_ClientMgrBinary_ConfigSection]
EventLoopPlugInImplType=Network
PoolMgrInitializer=ClientMgrInstPool
CoreId=10
[EventLoop_AdminClientMgr_ConfigSection]
EventLoopPlugInImplType=Network
PoolMgrInitializer=AdminClientMgrInstPool
CoreId=11
# RFAProvider (4)
[EventLoop_RFAClientMgr_ConfigSection]
#EventLoopPlugInImplType=ThirdParty
EventLoopPlugInImplType=Network
PoolMgrInitializer=ClientMgrInstPool
CoreId=12
-------------
Assigning core in logger.cfg
ThreadName=Logger
CoreId=13
----------
Assigning cores in stats:
CoreId=14
-----------
AWK to read GMDS stats
awk 'BEGIN {FS=","} {if($0 ~ /Base/){print} else if($0 ~ /GMD/) {printf "ID:%23s|MsgNo:%9s|Msg_aggNo:%12s|P10:%7s|P25:%7s|P50:%7s|P75:%7s|P90:%7s|P95:%7s|P99:%7s\n",$1,$2,$3,$11,$12,$13,$14,$15,$16,$17}}'
----------------------------------------------------------------------------------------------------------------------
LBM Monitoring 29West UMS Ultra Messaging 
UMPI - UMS ITRS plug-in runs on uk1qgmd02 - PreProd
Location: /opt/gmdemea/umpi/geneos-umpi-2.2.2/UMS_5.2/Linux_x86_64/glibc2.5
Symbolic link: /opt/gmdemea/umpi --> /opt/gmdemea/versions/umpi_versions/
Binary: geneos-umpi
Start Command: /opt/gmdemea/scripts/start_umpi.sh UltraMessaging-PreProd UltraMessaging-PreProd 'UM#MONITORING#EMEA#PreProd' /opt/gmdemea/lbm-monitoring/lbm_monitoring.cfg
Params:
1 - Sampler name
2 - Sampler topic
3 - LBM topic on which publishers and receivers send the statistics (UM#MONITORING#EMEA#PreProd)
4 - LBM Monitoring config: /opt/gmdemea/lbm-monitoring/lbm_monitoring.cfg
Start/Stop scripts:
/opt/gmdemea/scripts/start_umpi.sh
/opt/gmdemea/scripts/stop_umpi.sh
Crontab:
# LBM Monitoring - ITRS plugin restart
03 01 * * 1-5 /bin/bash /opt/gmdemea/scripts/stop_umpi.sh
03 02 * * 1-5 /bin/bash /opt/gmdemea/scripts/start_umpi.sh UltraMessaging-PreProd UltraMessaging-PreProd 'UM#MONITORING#EMEA#PreProd' /opt/gmdemea/lbm-monitoring/lbm_monitoring.cfg
ITRS rules set:
If we have alert it will stay yellow/red for 5 mins. after problem is gone and clear itself, we cannot set it to
clear manually because it is not working like this, it is stats based so if outOfOrder rate goes back to 0 it will clear alert.
To check previous instances of alerts go to View --> Event Tickers in ITRS, copy 'Dataview Row' value (which is a unique key) go to
receivers/sources and search for it.
-------------------------------------------------------------------
ITRS CPU monitoring set to average only:
On gateway editor look under:
Rules > Hardware > CPU > CPU Utilisation Average Only

You will see I added a rule to set all logical monitoring to undefined so it is not longer monitored.

ITRS change CPU avg load values for specific server:
load_average_fail - int - val
load_average_warn - int - val 
---------------------------------------------------------------------------------------------------------------------------
LBM Tools 29West UMS Ultra Messaging
/opt/gmdemea/utilities/mtools/x86_64/mdump 224.0.48.7 55200 - listen to mcast channel  
On uk1qgmd01 in /opt/gmdemea/scripts/LBM_Monitoring/bin are compiled tools (v6.2 we use 5.2 so some of this may not work) but below one works:
./bin/lbmwrcv -v -c /opt/gmdemea/lbm-monitoring/lbm_monitoring.cfg ".*" --> lbm receive allows to see all the trafic received with topic names and IP/PORT
===================================================================================================================================
RATES
SN Application: FLOW RATES ENGINEERING EUROPE | CSI Application Id: 155104
Prod servers (jump from uk1/2pgmd01):
uk1pfirates01.prod.lava - IP: 10.99.131.150, Port: 14101
uk2pfirates01.prod.lava - IP: 10.99.139.150, Port: 14101, Backup(BPIPE) Port: 14102
SolarFlare Optimization:
Rates Server Setup on uk1/2pfirates01. Changes implemented on 22nd May under REQU0000973021 [Piotr / Adam]
a.	Some of the changes implemented are as follows, but Piotr still assessing which are applicable for Rates setup:
i.	IRQs – 2 queues (rss_cpus=2) assigned to last two cores on numa node 0 ->  cores: 6,7 (that leave us 6 cores to run 2 instances for GMDS 3 cores each)
ii.	System cset – use first 2 cores on numa node 1 ->  cores 8,9 (that leaves 6 cores for Rates to use)  
iii.	Set net.ipv4.igmp_max_memberships = 100
 
Network:
Like on uk1/2pgmd13: 
bond0 internal
bond1 mcast for RDC (uk1pfirates01) - connected to FixNetix
eth2 mcast for CGC (uk2pfirates01) - connected to FixNetix
RATES FID: mkvprod --> sudo su mkvprod
Rates GMD manual build
Jump box: NY4DCoe01.dev.sti (169.176.42.215)
I have done checkout on ny111-llab07-1:/opt/cds/pp72492/gmd_rates:
SRLabs instalation: /opt/tools/installs/srlabs/
on ny111-llab07-1 cd /opt/cds/pp72492/gmd_rates
Jump box: NY4DCoe01.dev.sti (169.176.42.215)
svn checkout https://teamforgesvn.nam.nsroot.net/svn/repos/gmd/nam/branches/gmd_rates/ 
source /opt/cds/pp72492/.bashrc
bjam --enable_plugins=srlabs
Rates GMDS needs 4 cores - we can give it 3 cores and put SRLabs reader thread on same core as IRQs.
Rates performance testing log:
uk2pfirates01.prod.lava:/home/yb88010/RATES_JAVA_API/GMDClientAPI-0.0.9/log/GMDClientAPI_percentile_20150605.log
CDCMSGPROC config for Rates:
dist/bin/debug/cdcmsgproc -c /home/rn55679/working/cdcfg_cds_client_tcp/cdc.cfg &
This is on ny111-llab07
RATES NAM - CME
/opt/cds/${LOGNAME}/cfginstalls/current/scripts/cme-RefData.sh
only COB as of now
gr75gmd301b
gr75gmd301b.prod.lava
LOGNAME = cdsprod
Eurex Symbol - month char code mapping:
		monthNumToFutureMonthSym.put("01", "F"); --> Jan
		monthNumToFutureMonthSym.put("02", "G");
		monthNumToFutureMonthSym.put("03", "H");
		monthNumToFutureMonthSym.put("04", "J");
		monthNumToFutureMonthSym.put("05", "K");
		monthNumToFutureMonthSym.put("06", "M");
		monthNumToFutureMonthSym.put("07", "N");
		monthNumToFutureMonthSym.put("08", "Q");
		monthNumToFutureMonthSym.put("09", "U");
		monthNumToFutureMonthSym.put("10", "V");
		monthNumToFutureMonthSym.put("11", "X");
		monthNumToFutureMonthSym.put("12", "Z"); --> Dec
---------------------------------------------------------------------------------------------------------------------
SmartMap Overview
SmartMap creates mapping file (symbol files for feed handlers and StaticData for GMDS). 
This files are loaded by Feeds and GMDS. 
It tells feed handlers what to subscribe for and what is the mapping between RIC and exchange symbol 
(also takes care about aggregation (by RIC) for MTFs and multi-listed stocks), for GMDS it gives initial cache info.
---------------------------------------------------------------------------------------------------------------------
GMD Feed Handler GMDFH
uk1dgmd01
/opt/gmdemea/gmdfeedhandler/cds/dist* contains the build
----------------------------------------------------------------------------------------------------------------------
ICG Build
/opt/gmdemea/versions/ICGBuildAgent/bin  is the location of binaries 
./agent.sh start   [will start it]
./agent.sh stop [will stop it]
ps -ef | grep buildServer.agent - check if runs
ICG does probing on these configured agents and if it can not make connection then it shows disconnected 
There can be many reasons to it. one of them is agent process is not up
but after starting still its not able to do, then ICG team is the best to figure out 
GUI: https://teamcity.icgbuild.nam.nsroot.net/agentDetails.html?id=23&agentTypeId=23&realAgentName=NP_RH66_uk1dgmd01_2
-----------------------------------------------------------------------------------------------------------------------
ELK
This will cover:
•	What is Elastic Stack (ELK)
•	How do you get on board (https://collaborate.citi.net/docs/DOC-342926)
•	Benefits
•	Alternatives
Before the meeting here is some bedtime reading: 
•	Overview of Elastic Stack: https://collaborate.citi.net/groups/elastic-stack
-------------------------------------------------------------------------------------------------------------------------
GMD on GIT Stash / Bitbucket 
git clone with no SSL verify:
git -c http.sslVerify=false clone https://github.com/srctips/maven-tools.git
1.	To access BitBucket web interface (GIT repository)
https://cedt-icg-bitbucket.nam.nsroot.net/bitbucket/projects/GMD
--- Use your SOEID/SSO password.
                              
2.	Clone the GMDS project on Linux: 
git clone ssh://git@169.177.230.192:7999/gmd/gmds.git
        --- Currently we have to use IPs in place of host-name (cedt-icg-bitbucketcli.nam.nsroot.net) because firewall request is still pending. 
NOTE:
If authentication fails, generate ssh key in one of your development box (say ny111-llab07)
$ssh-keygen      --- It will create ssh key under directory /home/<soeid>/.ssh/
                                - Copy public key and add it to GIT account in server (https://cedt-icg-bitbucket.nam.nsroot.net/bitbucket/plugins/servlet/ssh/account/keys)
Please also setup your user name and email id (on Linux box) for git check-ins:
                $git config --global user.name "devendra chandola"
                $git config --global user.email "devendra.chandola@citi.com"
				
Checkout / Checking process:
1. Clone the code to local directory (to get the link go to BitBucket find the branch and klick on '...' button and select clone): git clone ssh://git@cedt-icg-bitbucketcli.nam.nsroot.net:7999/gmdtest/gmds.git
2. Checkout code from develop branch to change branch called mytest_branch here: git checkout -b mytest_branch origin/develop
   To check if you are on right branch run: git branch
3. Check in to local repository: git add testing.cpp and: git checkin
4. Commit to remote server: git push origin mytest_branch
5. Go to BitBucket: https://cedt-icg-bitbucket.nam.nsroot.net/bitbucket/projects , find project and got to your new branch
6. Create pull request (review your change): Click on 'Create pull request' button in BitBucket, add reviewers and description and click 'Create'
7. Once pull request is approved you can merge to develop branch by clicking at 'merge' button in BitBuscket

git stash stashing
If you have half done changes you can stage and stash them with: git stash and then change branch and work on something else.
git stash
git stash list - see stashed stuff
	$ git stash list
	stash@{0}: WIP on master: 049d078 added the index file
	stash@{1}: WIP on master: c264051 Revert "added file_size"
	stash@{2}: WIP on master: 21d80a5 added number to log
git stash apply - apply last stashed change (stash@{0})
git stash apply stash@{2} - to apply older version specify which, default applies most recent one.

git show <commit or file name>
# Show files changed in commit
git show --pretty="" --name-only <commit>
git blame <file name>

git resolving merge conflicts
 - Pull the destination branch into the source branch. At this point, pulling the destination will try to merge it with the source and reveal all the conflicts.
   git pull origin <destination_branch>

git rm --cached <file> remove file from remote repo. but not locally
git reset - revert git add

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
XENV STI Firewall
powiem Ci tak - mam przeczucie, ze wystarczy otworzyc port 111 do 150.110.109.54 - to jest /xenv server w namie, 
ktorego uzywaja nasze hosty w sti z namu, tam jest ten port otwarty, u Ciebie wisi
wiec mozesz w miedzy czasie sprobowac juz to pogonic z FW teamem, a w miedzy czasie tutaj moze sie cos wyjasni
Request - REQU0002585581

XENV - mounted on llab07
---------------------------------------------------------------------------------------------------------------------
Import (open) existing maven project in Eclipse:
Open eclipse.
Click File > Import.
Type Maven in the search box under Select an import source:
Select Existing Maven Projects.
Click Next.
Click Browse and select the folder that is the root of the Maven project (probably contains the pom.xml file)
Click OK.
-------------------------
Proxy settings for eclipse neon 
open Preferences, search for Proxy, select Network Connections. Then select the top HTTP line, click Edit, add webproxy.ssmb.com and 8080, select Authentication tickbox and enter your windows login details.
Finally change the Active Provider dropdown to Manual which will select the proxy settings you have just entered.
Just sometimes I have seen that it works only if you add it just after Vmargs. 
eg 
-vm
C:/Program Files/Java/jdk1.8.0_121/bin/javaw.exe
-vmargs
-Dorg.eclipse.ecf.provider.filetransfer.excludeContributors=org.eclipse.ecf.provider.filetransfer.httpclient4
-Dosgi.requiredJavaVersion=1.8
-----------------------------------------------------------------------------------------------------------------------
Using VIMDIFF for GIT DIFF
Step 1: add this to your .gitconfig
[diff]
  external = git_diff_wrapper
[pager]
  diff =
  
Step 2: create a file named git_diff_wrapper, put it somewhere in your $PATH
#!/bin/sh
vimdiff "$2" "$5"
I still have access to the default git diff behavior with the --no-ext-diff flag. Here’s a function I put in my bash configuration files:
function git_diff() {
  git diff --no-ext-diff -w "$@" | vim -R –
}

vimdiff output to HTML:
:help :TOhtml

vimdiff - use [c and ]c to go to the previous or next difference

------------------------------------------------------------------------------------------------------------------------
Eurex source switching using BPIPE
Test subscription:
/opt/gmdemea/tools/scripts/rmdstestclient -u gmdemea -S BPIPE -f /opt/gmdemea/tools/RFA_sym_files/xeurTestSyms -h cwu-p2ps1.eur.nsroot.net -ct rssl -X -d 3 -v

/opt/gmdemea/scripts/qbus_startlab.sh -f xeur -m XEUR-BPIPE -d 0

/opt/gmdemea/scripts/gmdserver_start.sh -f eurex-backup-gmdserver -gmdsType server -assetCls future -smPath /opt/gmdemea/smartmap_V2/maps/futures/eurex/ -smArchPath /opt/loghome/gmdemea/archive/smartmap/futures/eurex/

XEUR,DE0009652644.EUR.XEUR,FGBLM8,FGBLM8,syRXM8.EUX,FGBL201806,false,future,
XEUR,DE0009652644..XEUR,FGBLM8-U8,FGBLM8-U8,syRXM8RXU8.EUX,72060548975427622,false,spread,
XEUR,DE0009652636..XEUR,FGBXM8-U8,FGBXM8-U8,syUBM8UBU8.EUX,72060561860329510,false,spread,

--------------------------------------------------------------------------------------------------------------------------
Regex matching in a bash if statement

https://stackoverflow.com/questions/18709962/regex-matching-in-a-bash-if-statement/18710850#18710850

There are a couple of important things to know about bash's [[ ]] construction. The first:
Word splitting and pathname expansion are not performed on the words between the [[ and ]]; tilde expansion, parameter and variable expansion, 
arithmetic expansion, command substitution, process substitution, and quote removal are performed.

The second thing:
An additional binary operator, ‘=~’, is available,... the string to the right of the operator is considered an extended regular expression and matched accordingly... 
Any part of the pattern may be quoted to force it to be matched as a string.

Consequently, $v on either side of the =~ will be expanded to the value of that variable, but the result will not be word-split or pathname-expanded. 
In other words, it's perfectly safe to leave variable expansions unquoted on the left-hand side, but you need to know that variable expansions will happen on the right-hand side.

So if you write: [[ $x =~ [$0-9a-zA-Z] ]], the $0 inside the regex on the right will be expanded before the regex is interpreted, 
which will probably cause the regex to fail to compile (unless the expansion of $0 ends with a digit or punctuation symbol whose ascii value is less than a digit). 
If you quote the right-hand side like-so [[ $x =~ "[$0-9a-zA-Z]" ]], then the right-hand side will be treated as an ordinary string, 
not a regex (and $0 will still be expanded). What you really want in this case is [[ $x =~ [\$0-9a-zA-Z] ]]

Similarly, the expression between the [[ and ]] is split into words before the regex is interpreted. 
So spaces in the regex need to be escaped or quoted. 
If you wanted to match letters, digits or spaces you could use: [[ $x =~ [0-9a-zA-Z\ ] ]]. 
Other characters similarly need to be escaped, like #, which would start a comment if not quoted. 
Of course, you can put the pattern into a variable:
pat="[0-9a-zA-Z ]"
if [[ $x =~ $pat ]]; then ...
For regexes which contain lots of characters which would need to be escaped or quoted to pass through bash's lexer, many people prefer this style. 
But beware: In this case, you cannot quote the variable expansion:
# This doesn't work:
if [[ $x =~ "$pat" ]]; then ...
Finally, I think what you are trying to do is to verify that the variable only contains valid characters. 
The easiest way to do this check is to make sure that it does not contain an invalid character. In other words, an expression like this:

valid='0-9a-zA-Z $%&#' # add almost whatever else you want to allow to the list
if [[ ! $x =~ [^$valid] ]]; then ...
! negates the test, turning it into a "does not match" operator, and a [^...] regex character class means "any character other than ...".

The combination of parameter expansion and regex operators can make bash regular expression syntax "almost readable", but there are still some gotchas. 
(Aren't there always?) One is that you could not put ] into $valid, even if $valid were quoted, except at the very beginning. 
(That's a Posix regex rule: if you want to include ] in a character class, it needs to go at the beginning. 
- can go at the beginning or the end, so if you need both ] and -, you need to start with ] and end with -, leading to the regex "I know what I'm doing" emoticon: [][-])
--------------------------------------------------
Bash brackets, parentheses, double brackets etc..
In Bash, test and [ are builtins.

The double bracket enables additional functionality. For example, you can use && and || instead of -a and -o and there's a regular expression matching operator =~.
The braces, in addition to delimiting a variable name are used for parameter expansion so you can do things like:

Truncate the contents of a variable
$ var="abcde"; echo ${var%d*}
abc

Make substitutions similar to sed
$ var="abcde"; echo ${var/de/12}
abc12

Use a default value
$ default="hello"; unset var; echo ${var:-$default}
hello

and several more

Also, brace expansions create lists of strings which are typically iterated over in loops:
$ echo f{oo,ee,a}d
food feed fad

$ mv error.log{,.OLD}
(error.log is renamed to error.log.OLD because the brace expression
expands to "mv error.log error.log.OLD")

$ for num in {000..2}; do echo "$num"; done
000
001
002

$ echo {00..8..2}
00 02 04 06 08

$ echo {D..T..4}
D H L P T
Note that the leading zero and increment features weren't available before Bash 4.

Thanks to gboffi for reminding me about brace expansions.

Double parentheses are used for arithmetic operations:
((a++))
((meaning = 42))
for ((i=0; i<10; i++))
echo $((a + b + (14 * c)))
and they enable you to omit the dollar signs on integer and array variables and include spaces around operators for readability.

Single brackets are also used for array indices:
array[4]="hello"
element=${array[index]}
Curly brace are required for (most/all?) array references on the right hand side.

ephemient's comment reminded me that parentheses are also used for subshells. And that they are used to create arrays.
array=(1 2 3)
echo ${array[1]}
2 

--------------------------------------------------------------------------------------------------------------------------
Java Chronicle:
Chronicle :https://chronicle.software/products/#map
Citi MicroService Competency Centre: https://icgshare.eur.citi.net/sites/CELT/_layouts/15/start.aspx#/SitePages/Microservices%20Competency%20Centre.aspx
Bitbucket repo with demos: https://cedt-icg-bitbucket.nam.nsroot.net/bitbucket/projects/MICRO/repos/microservices-demo/browse
Java Doc: http://openhft.github.io/Chronicle-Engine/apidocs/
